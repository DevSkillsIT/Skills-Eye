# ğŸ“‹ PLANO DE REFATORAÃ‡ÃƒO SKILLS EYE - VERSÃƒO COMPLETA 2.0

**Data:** 13/11/2025  
**VersÃ£o:** 2.0 - Baseada no Projeto Real  
**Autor:** AnÃ¡lise TÃ©cnica Completa com Pesquisa Web  
**Status:** ğŸ”´ DOCUMENTO DEFINITIVO PARA IMPLEMENTAÃ‡ÃƒO

---

## ğŸ“‘ ÃNDICE

1. [SUMÃRIO EXECUTIVO](#sumÃ¡rio-executivo)
2. [ANÃLISE DO PROJETO ATUAL](#anÃ¡lise-do-projeto-atual)
3. [RECOMENDAÃ‡Ã•ES TÃ‰CNICAS FUNDAMENTAIS](#recomendaÃ§Ãµes-tÃ©cnicas-fundamentais)
4. [ARQUITETURA PROPOSTA](#arquitetura-proposta)
5. [COMPONENTES A CRIAR](#componentes-a-criar)
6. [PLANO DE IMPLEMENTAÃ‡ÃƒO DETALHADO](#plano-de-implementaÃ§Ã£o-detalhado)
7. [VALIDAÃ‡ÃƒO E TESTES](#validaÃ§Ã£o-e-testes)
8. [DOCUMENTAÃ‡ÃƒO NECESSÃRIA](#documentaÃ§Ã£o-necessÃ¡ria)

---

## ğŸ¯ SUMÃRIO EXECUTIVO

### SituaÃ§Ã£o Atual

O **Skills Eye** jÃ¡ possui **80% da arquitetura dinÃ¢mica necessÃ¡ria** funcionando corretamente:

âœ… **Backend com extraÃ§Ã£o dinÃ¢mica** via `monitoring_types_dynamic.py`  
âœ… **Sistema de metadata fields dinÃ¢micos** via `metadata_fields_manager.py`  
âœ… **PÃ¡ginas Services e BlackboxTargets** funcionais com ProTable  
âœ… **Hooks reutilizÃ¡veis** `useMetadataFields`, `useReferenceValues`, `useServiceTags`  
âœ… **Multi-servidor SSH** para extraÃ§Ã£o de configuraÃ§Ãµes Prometheus  
âœ… **Sistema de cache** no Consul KV  

### O Que Precisa Ser Feito

**NÃƒO Ã© uma refatoraÃ§Ã£o completa** - Ã© uma **EXPANSÃƒO** do sistema existente para criar 4 novas pÃ¡ginas de monitoramento e melhorar alguns componentes do backend:

1. **4 PÃ¡ginas Frontend** â†’ NetworkProbes, WebProbes, SystemExporters, DatabaseExporters
2. **Componente React GenÃ©rico** â†’ `DynamicMonitoringPage.tsx` (reutilizÃ¡vel)
3. **Melhorias no Backend** â†’ Cache KV dos tipos, categorization rules JSON, query builder
4. **Endpoints Dual** â†’ `/api/v1/monitoring/data` (Consul) + `/api/v1/monitoring/metrics` (Prometheus)

### Objetivos SMART

- âœ… **S**pecÃ­fico: Criar 4 pÃ¡ginas de monitoramento 100% dinÃ¢micas
- âœ… **M**ensurÃ¡vel: 0 hardcodes, 100% baseado em KV/Prometheus
- âœ… **A**tingÃ­vel: Reaproveitar 80% do cÃ³digo existente
- âœ… **R**elevante: Facilitar gestÃ£o de diferentes tipos de monitoramento
- âœ… **T**emporal: 12-13 dias de implementaÃ§Ã£o

---

## ğŸ” ANÃLISE DO PROJETO ATUAL

### 2.1 Backend Python - O Que JÃ EXISTE

#### âœ… Arquivo: `monitoring_types_dynamic.py` (456 linhas)

**O que FAZ:**
- Extrai tipos de monitoramento **DINAMICAMENTE** do `prometheus.yml`
- Categoriza automaticamente em 8 categorias prÃ©-definidas
- Funciona com mÃºltiplos servidores Prometheus via SSH
- Infere categoria baseado em job_name e metrics_path

**Endpoint disponÃ­vel:**
```python
GET /api/v1/monitoring-types-dynamic/from-prometheus?server=ALL
```

**Resposta atual:**
```json
{
  "success": true,
  "servers": {
    "172.16.1.26": {
      "types": [
        {
          "id": "icmp",
          "display_name": "ICMP (Ping)",
          "category": "network-probes",
          "job_name": "icmp",
          "exporter_type": "blackbox",
          "module": "icmp",
          "fields": ["company", "project", "env", "name", "instance"],
          "metrics_path": "/probe",
          "server": "172.16.1.26"
        }
      ],
      "total": 15
    }
  },
  "categories": [
    {
      "category": "network-probes",
      "display_name": "Network Probes (Rede)",
      "types": [...]
    }
  ],
  "all_types": [...],
  "total_types": 15
}
```

**Categorias suportadas:**
1. `network-probes` â†’ ICMP, TCP, DNS, SSH
2. `web-probes` â†’ HTTP 2xx, HTTP 4xx, HTTPS, POST
3. `system-exporters` â†’ Node, Windows, SNMP
4. `database-exporters` â†’ MySQL, PostgreSQL, Redis, MongoDB
5. `infrastructure-exporters` â†’ HAProxy, Nginx, Kafka, RabbitMQ
6. `hardware-exporters` â†’ IPMI, Dell HW
7. `network-devices` â†’ MikroTik (MKTXP)
8. `custom-exporters` â†’ Qualquer outro job

**FunÃ§Ã£o de inferÃªncia:**
```python
def _infer_category_and_type(job_name: str, job_config: Dict) -> tuple:
    """
    Infere categoria baseado em:
    1. Nome do job (blackbox, node, mysql, etc)
    2. metrics_path (/probe = blackbox, /metrics = exporter)
    3. PadrÃµes conhecidos (haproxy, nginx, kafka, etc)
    """
    job_lower = job_name.lower()
    metrics_path = job_config.get('metrics_path', '/metrics')
    
    # Blackbox detection
    is_blackbox = (
        'blackbox' in job_lower or
        metrics_path == '/probe' or
        job_lower in ['http_2xx', 'icmp', 'tcp_connect', ...]
    )
    
    if is_blackbox:
        module = _extract_blackbox_module(job_config)
        if module in ['icmp', 'tcp', 'dns', 'ssh']:
            return 'network-probes', {...}
        else:
            return 'web-probes', {...}
    
    # Node Exporter
    if 'node' in job_lower or 'selfnode' in job_lower:
        return 'system-exporters', {...}
    
    # ... (continua para outros exporters)
```

**âœ… PONTO CRÃTICO:** Este cÃ³digo **JÃ FAZ 90%** do que o documento original propunha! NÃ£o precisa ser reescrito, apenas **MELHORADO** e **PERSISTIDO NO KV**.

---

#### âœ… Arquivo: `metadata_fields_manager.py` (122 linhas)

**O que FAZ:**
- Extrai campos metadata dos `relabel_configs` do Prometheus
- Salva no Consul KV: `skills/eye/metadata/fields`
- Sistema de cache com TTL de 5 minutos
- Suporta mÃºltiplos servidores com SSH + TAR (ultra-rÃ¡pido)

**Endpoint disponÃ­vel:**
```python
GET /api/v1/metadata-fields/sync-status?server_id=172.16.1.26:5522
```

**âš ï¸ IMPORTANTE:** O modelo `MetadataFieldModel` **JÃ TEM** 3 propriedades `show_in_*`:
```python
class MetadataFieldModel(BaseModel):
    # ... campos existentes ...
    
    # âœ… JÃ EXISTEM (linhas 72-74):
    show_in_services: bool = Field(True, description="Mostrar na pÃ¡gina Services")
    show_in_exporters: bool = Field(True, description="Mostrar na pÃ¡gina Exporters")
    show_in_blackbox: bool = Field(True, description="Mostrar na pÃ¡gina Blackbox")
```

**ğŸ”§ AÃ‡ÃƒO NECESSÃRIA:** Adicionar **4 NOVAS** propriedades (Dia 3):
```python
    # â­ ADICIONAR estas 4 novas:
    show_in_network_probes: bool = Field(True, description="Mostrar na pÃ¡gina Network Probes")
    show_in_web_probes: bool = Field(True, description="Mostrar na pÃ¡gina Web Probes")
    show_in_system_exporters: bool = Field(True, description="Mostrar na pÃ¡gina System Exporters")
    show_in_database_exporters: bool = Field(True, description="Mostrar na pÃ¡gina Database Exporters")
```

**Estrutura KV atual:**
```json
{
  "version": "2.0.0",
  "last_updated": "2025-11-13T10:30:00",
  "total_fields": 22,
  "fields": [
    {
      "name": "company",
      "display_name": "Empresa",
      "category": "business",
      "field_type": "string",
      "show_in_services": true,
      "show_in_blackbox": true,
      "show_in_table": true,
      "show_in_filter": true,
      "required": true
    }
  ]
}
```

**âœ… PONTO CRÃTICO:** Sistema de metadata fields **JÃ Ã‰ DINÃ‚MICO** e funciona perfeitamente!

---

#### âœ… Arquivo: `consul_manager.py` (1034 linhas)

**O que FAZ:**
- Cliente async do Consul via httpx (nÃ£o usa biblioteca python-consul)
- Gerencia Services, KV, Nodes, Health Checks
- Sistema de retry com backoff exponencial
- ValidaÃ§Ã£o de dados com Pydantic

**MÃ©todos principais:**
```python
class ConsulManager:
    async def get_json(self, key: str) -> Optional[Dict]
    async def put_json(self, key: str, value: Dict) -> bool
    async def get_services_list(self) -> List[Dict]
    async def register_service(self, payload: ServiceCreatePayload) -> bool
```

**âœ… PONTO CRÃTICO:** JÃ¡ usa **API REST direta** com httpx async - **NÃƒO PRECISA migrar** para biblioteca python-consul!

---

### 2.2 Frontend React - O Que JÃ EXISTE

#### âœ… Arquivo: `Services.tsx` (1552 linhas)

**âš ï¸ IMPORTANTE:** Services.tsx e BlackboxTargets.tsx sÃ£o **APENAS REFERÃŠNCIA** - novas pÃ¡ginas usarÃ£o lÃ³gica diferente!

**O que FAZ:**
- Lista todos os serviÃ§os Consul com metadata dinÃ¢micos
- Usa `useTableFields('services')` para colunas dinÃ¢micas
- Usa `useFormFields('services')` para formulÃ¡rio dinÃ¢mico
- Usa `useFilterFields('services')` para filtros dinÃ¢micos
- Sistema de auto-cadastro com `useBatchEnsure` e `useServiceTags`

**Hooks utilizados:**
```typescript
const { tableFields } = useTableFields('services');  // 22 campos dinÃ¢micos
const { formFields } = useFormFields('services');    // FormulÃ¡rio adaptÃ¡vel
const { filterFields } = useFilterFields('services'); // Filtros adaptÃ¡veis
```

**Estrutura de colunas dinÃ¢micas:**
```typescript
const defaultColumnConfig = useMemo<ColumnConfig[]>(() => {
  // Combina colunas fixas + campos metadata dinÃ¢micos
  const metadataColumns: ColumnConfig[] = tableFields.map((field) => ({
    key: field.name,
    title: field.display_name,
    visible: field.show_in_table ?? true
  }));
  
  return [
    ...FIXED_COLUMNS,      // node, service, id, address, port, tags, actions
    ...metadataColumns     // company, project, env, name, instance, etc
  ];
}, [tableFields]);
```

**âœ… PONTO CRÃTICO:** Services.tsx **JÃ Ã‰ UM MODELO PERFEITO** de como fazer pÃ¡gina dinÃ¢mica! As 4 novas pÃ¡ginas devem seguir este padrÃ£o.

---

#### âœ… Arquivo: `BlackboxTargets.tsx` (1330 linhas)

**O que FAZ:**
- Lista targets do Blackbox Exporter com metadata dinÃ¢micos
- Mesma estrutura de hooks que Services.tsx
- ProTable com colunas configurÃ¡veis via ColumnSelector
- Filtros avanÃ§ados com AdvancedSearchPanel

**âœ… PONTO CRÃTICO:** BlackboxTargets.tsx Ã© praticamente **IDENTICAL** ao Services.tsx em estrutura - confirma que o padrÃ£o funciona bem!

---

#### âœ… Arquivo: `useMetadataFields.ts` (478 linhas)

**O que FAZ:**
- Hook customizado que busca campos metadata do backend
- Cache global de 5 minutos para evitar requests repetidos
- Filtra campos baseado em contexto (`services`, `blackbox`, etc)

**ImplementaÃ§Ã£o atual:**
```typescript
export function useTableFields(context: 'services' | 'blackbox') {
  const [fields, setFields] = useState<MetadataField[]>([]);
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    async function loadFields() {
      const response = await fetch('/api/v1/metadata-fields/fields');
      const data = await response.json();
      
      // Filtrar campos baseado no contexto
      const filtered = data.fields.filter((field) => {
        if (context === 'services') {
          return field.show_in_services !== false;
        } else if (context === 'blackbox') {
          return field.show_in_blackbox !== false;
        }
        return true;
      });
      
      setFields(filtered);
      setLoading(false);
    }
    
    loadFields();
  }, [context]);
  
  return { tableFields: fields, loading };
}
```

**âœ… PONTO CRÃTICO:** Hook **JÃ ACEITA CONTEXTO** mas sÃ³ suporta 'services' e 'blackbox'. Precisa aceitar contextos dinÃ¢micos como 'network-probes', 'web-probes', etc.

---

### 2.3 Multi-Config Manager (SSH + YAML Parsing)

#### âœ… Arquivo: `multi_config_manager.py` (2034 linhas)

**O que FAZ:**
- Conecta via SSH em mÃºltiplos servidores Prometheus
- LÃª e escreve arquivos YAML preservando comentÃ¡rios (ruamel.yaml)
- ExtraÃ§Ã£o ultra-rÃ¡pida com AsyncSSH + TAR (2-3 segundos)
- ValidaÃ§Ã£o com promtool antes de aplicar mudanÃ§as

**MÃ©todo crÃ­tico:**
```python
async def extract_all_fields_with_asyncssh_tar(self) -> Dict:
    """
    Extrai campos de TODOS os servidores Prometheus via AsyncSSH + TAR
    
    Performance:
    - MÃ©todo antigo (SSH sequencial): 20-30 segundos
    - MÃ©todo atual (AsyncSSH + TAR): 2-3 segundos
    
    Returns:
        {
            'fields': [MetadataField(...), ...],
            'total_fields': 22,
            'successful_servers': 3,
            'total_servers': 3
        }
    """
```

**âœ… PONTO CRÃTICO:** Sistema de extraÃ§Ã£o **JÃ Ã‰ ALTAMENTE OTIMIZADO** e funciona perfeitamente!

---

## ğŸ”¬ RECOMENDAÃ‡Ã•ES TÃ‰CNICAS FUNDAMENTAIS

### 3.1 Biblioteca python-consul vs. API REST Direta

**RECOMENDAÃ‡ÃƒO: MANTER API REST DIRETA (httpx)**

#### AnÃ¡lise da SituaÃ§Ã£o

**Biblioteca python-consul:**
- âŒ **Abandonada desde 2018** - Ãºltima atualizaÃ§Ã£o oficial
- âŒ **Forks fragmentados** - py-consul (Criteo), python-consul2, consulate
- âŒ **Suporte incompleto** - nÃ£o expÃµe todas as APIs do Consul 1.15+
- âŒ **DependÃªncia adicional** - aumenta surface de bugs
- âœ… AbstraÃ§Ã£o mais limpa (sintaxe simplificada)

**API REST direta (httpx):**
- âœ… **Sempre atualizada** - segue API oficial do Consul
- âœ… **Controle total** - acesso a TODAS as features
- âœ… **Performance** - httpx async Ã© extremamente rÃ¡pido
- âœ… **JÃ IMPLEMENTADO** - consul_manager.py usa httpx
- âœ… **Menor dependÃªncia** - menos bibliotecas terceiras
- âŒ CÃ³digo mais verboso (mais linhas)

#### Pesquisa Web - Estado Atual (2025)

Segundo documentaÃ§Ã£o oficial do HashiCorp (Libraries and SDKs - HTTP API):
- Python nÃ£o tem biblioteca **OFICIALMENTE mantida** pela HashiCorp
- Bibliotecas da comunidade estÃ£o **fragmentadas e desatualizadas**
- RecomendaÃ§Ã£o oficial: **usar HTTP API diretamente**

#### ConclusÃ£o

**âœ… MANTER httpx com API REST direta**

Justificativa:
1. Sistema atual **JÃ FUNCIONA PERFEITAMENTE** com httpx
2. Migrar para biblioteca abandonada Ã© **PIOR** que o atual
3. Controle total sobre requisiÃ§Ãµes e respostas
4. Performance excelente com async/await

**AÃ§Ã£o: NENHUMA** - nÃ£o migrar para python-consul

---

### 3.2 ValidaÃ§Ã£o: Sistema DinÃ¢mico Suporta TODOS os Exporters?

**RESPOSTA: SIM, COM RESSALVAS**

#### AnÃ¡lise Baseada em Pesquisa Web

Segundo documentaÃ§Ã£o oficial do Prometheus, existem **100+ exporters** oficiais e da comunidade:

**Exporters Oficiais (mantidos pela Prometheus GitHub org):**
- node_exporter (Linux/Unix)
- blackbox_exporter (probes)
- mysqld_exporter
- postgres_exporter
- redis_exporter
- haproxy_exporter
- memcached_exporter
- consul_exporter
- jmx_exporter
- snmp_exporter

**Exporters Populares da Comunidade:**
- windows_exporter (WMI)
- mongodb_exporter
- elasticsearch_exporter
- kafka_exporter
- nginx_exporter
- rabbitmq_exporter
- mktxp (MikroTik)
- ipmi_exporter

#### Como o Sistema Atual Trata Exporters

O `monitoring_types_dynamic.py` categoriza exporters baseado em:

1. **Job name pattern matching** - detecta palavras-chave (mysql, node, blackbox, etc)
2. **metrics_path** - `/probe` = blackbox, `/metrics` = exporter
3. **Lista de padrÃµes conhecidos** - 40+ padrÃµes hardcoded

```python
exporter_patterns = {
    'haproxy': ('infrastructure-exporters', 'HAProxy Exporter', 'haproxy_exporter'),
    'nginx': ('infrastructure-exporters', 'Nginx Exporter', 'nginx_exporter'),
    'kafka': ('infrastructure-exporters', 'Kafka Exporter', 'kafka_exporter'),
    # ... 40+ padrÃµes
}
```

**Problema:** Novos exporters **NÃƒO CONHECIDOS** caem em `custom-exporters`

#### SoluÃ§Ã£o Proposta

**Sistema deve ser AGNÃ“STICO ao tipo de exporter:**

1. **Regras de categorizaÃ§Ã£o no KV** (nÃ£o hardcoded)
2. **Sistema de "plugin"** onde novos exporters podem ser adicionados via JSON
3. **Fallback inteligente** - se nÃ£o conhece, usa custom-exporters

**âœ… CONCLUSÃƒO:** Sistema atual **FUNCIONA** mas pode ser **MELHORADO** com regras JSON no KV.

---

### 3.3 Cache KV dos Tipos de Monitoramento

**RECOMENDAÃ‡ÃƒO: IMPLEMENTAR CACHE KV COM TTL**

#### SituaÃ§Ã£o Atual

O `monitoring_types_dynamic.py` **NÃƒO salva** no KV - extrai sempre do Prometheus via SSH.

**Problema:**
- Cada request faz SSH para servidores Prometheus
- Lento (2-3 segundos por request)
- Sobrecarga desnecessÃ¡ria

**SoluÃ§Ã£o:**

1. **Primeira extraÃ§Ã£o** - salva resultado no KV
2. **Requests subsequentes** - lÃª do KV (< 100ms)
3. **TTL de 5 minutos** - revalida periodicamente
4. **BotÃ£o "Sincronizar"** - forÃ§a extraÃ§Ã£o nova

**Estrutura KV proposta:**
```
skills/eye/monitoring-types/cache.json
```

```json
{
  "version": "1.0.0",
  "last_updated": "2025-11-13T10:30:00",
  "ttl_seconds": 300,
  "servers": {
    "172.16.1.26": {
      "types": [...],
      "total": 15
    }
  },
  "categories": [...],
  "all_types": [...]
}
```

**ImplementaÃ§Ã£o:**

```python
async def get_monitoring_types_cached(server: Optional[str] = None):
    """
    Busca tipos de monitoramento com cache KV
    
    Fluxo:
    1. Tenta ler do KV
    2. Se cache vÃ¡lido (< 5 min), retorna
    3. Se cache expirado ou nÃ£o existe, extrai do Prometheus
    4. Salva no KV e retorna
    """
    cache_key = 'skills/eye/monitoring-types/cache.json'
    
    # STEP 1: Tentar ler do cache
    cached = await kv_manager.get_json(cache_key)
    
    if cached:
        last_updated = datetime.fromisoformat(cached['last_updated'])
        age_seconds = (datetime.now() - last_updated).total_seconds()
        
        if age_seconds < cached.get('ttl_seconds', 300):
            logger.info(f"[CACHE HIT] Usando tipos em cache (age={age_seconds}s)")
            return cached
    
    # STEP 2: Cache miss ou expirado - extrair do Prometheus
    logger.info("[CACHE MISS] Extraindo tipos do Prometheus via SSH...")
    result = await extract_types_from_all_servers(server)
    
    # STEP 3: Salvar no KV
    cache_data = {
        "version": "1.0.0",
        "last_updated": datetime.now().isoformat(),
        "ttl_seconds": 300,
        **result
    }
    
    await kv_manager.put_json(cache_key, cache_data)
    logger.info("[CACHE WRITE] Tipos salvos no KV")
    
    return cache_data
```

**âœ… AÃ‡ÃƒO: IMPLEMENTAR** este cache no `monitoring_types_dynamic.py`

---

### 3.4 Hooks: GenÃ©rico vs. Contextos EspecÃ­ficos?

**RECOMENDAÃ‡ÃƒO: HOOK GENÃ‰RICO COM CONTEXTO DINÃ‚MICO**

#### AnÃ¡lise das OpÃ§Ãµes

**OpÃ§Ã£o A: Contextos especÃ­ficos hardcoded**
```typescript
useTableFields('services')
useTableFields('blackbox')
useTableFields('network-probes')  // NOVO
useTableFields('web-probes')      // NOVO
useTableFields('system-exporters')  // NOVO
useTableFields('database-exporters')  // NOVO
```

âŒ Problema: Adicionar novo tipo requer mudanÃ§a no cÃ³digo

**OpÃ§Ã£o B: Hook genÃ©rico que aceita QUALQUER contexto**
```typescript
useTableFields(context: string)  // Aceita QUALQUER string
```

âœ… Vantagem: 100% dinÃ¢mico, funciona com qualquer categoria

#### ImplementaÃ§Ã£o Proposta

**Hook deve:**
1. Aceitar contexto como string genÃ©rica
2. Buscar campos do backend
3. Filtrar baseado em convenÃ§Ã£o: `show_in_{context}`

```typescript
export function useTableFields(context: string) {
  const [fields, setFields] = useState<MetadataField[]>([]);
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    async function loadFields() {
      // Buscar campos do backend
      const response = await fetch('/api/v1/metadata-fields/fields');
      const data = await response.json();
      
      // Filtrar baseado em show_in_{context}
      const showInKey = `show_in_${context.replace(/-/g, '_')}`;
      
      const filtered = data.fields.filter((field) => {
        // Se campo nÃ£o tem a propriedade show_in_{context}, exibe por padrÃ£o
        if (!(showInKey in field)) {
          return true;
        }
        return field[showInKey] !== false;
      });
      
      setFields(filtered);
      setLoading(false);
    }
    
    loadFields();
  }, [context]);
  
  return { tableFields: fields, loading };
}
```

**Uso:**
```typescript
// PÃ¡ginas existentes (mantÃ©m compatibilidade)
useTableFields('services')
useTableFields('blackbox')

// Novas pÃ¡ginas (funciona automaticamente)
useTableFields('network-probes')
useTableFields('web-probes')
useTableFields('system-exporters')
useTableFields('database-exporters')

// Futuras categorias (sem cÃ³digo adicional)
useTableFields('custom-exporters')
useTableFields('hardware-exporters')
```

**âœ… AÃ‡ÃƒO: IMPLEMENTAR** hook genÃ©rico conforme especificaÃ§Ã£o acima

---

## ğŸ—ï¸ ARQUITETURA PROPOSTA

### 4.1 Diagrama Geral do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONSUL KV STORE                               â”‚
â”‚                                                                  â”‚
â”‚  skills/eye/                                                     â”‚
â”‚  â”œâ”€â”€ monitoring-types/                                           â”‚
â”‚  â”‚   â”œâ”€â”€ cache.json              â† NOVO: Cache dos tipos        â”‚
â”‚  â”‚   â””â”€â”€ categorization/                                         â”‚
â”‚  â”‚       â””â”€â”€ rules.json          â† NOVO: Regras JSON            â”‚
â”‚  â”œâ”€â”€ metadata/                                                   â”‚
â”‚  â”‚   â””â”€â”€ fields                  â† JÃ EXISTE: 22 campos         â”‚
â”‚  â””â”€â”€ reference-values/            â† JÃ EXISTE: Auto-cadastro    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                            â†“ (httpx async)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND PYTHON (FastAPI)                            â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ ConsulKVConfig       â”‚  â”‚ MonitoringTypes        â”‚          â”‚
â”‚  â”‚ Manager (NOVO)       â”‚â†’ â”‚ Dynamic (MELHORADO)    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Categorization       â”‚  â”‚ DynamicQuery           â”‚          â”‚
â”‚  â”‚ RuleEngine (NOVO)    â”‚  â”‚ Builder (NOVO)         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â”‚  API Endpoints:                                                  â”‚
â”‚  - GET /api/v1/monitoring-types-dynamic/from-prometheus         â”‚
â”‚  - GET /api/v1/monitoring/data?category=network-probes (NOVO)   â”‚
â”‚  - POST /api/v1/monitoring-types-dynamic/sync-cache (NOVO)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                            â†“ (JSON)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FRONTEND REACT (Ant Design Pro)                     â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚     DynamicMonitoringPage (NOVO)         â”‚                  â”‚
â”‚  â”‚     (Componente Base Ãšnico)              â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                  â”‚
â”‚  PÃ¡ginas Geradas Automaticamente:                               â”‚
â”‚  - /monitoring/network-probes    (NOVA)                         â”‚
â”‚  - /monitoring/web-probes        (NOVA)                         â”‚
â”‚  - /monitoring/system-exporters  (NOVA)                         â”‚
â”‚  - /monitoring/database-exporters (NOVA)                        â”‚
â”‚                                                                  â”‚
â”‚  - /services                     (EXISTENTE - backup)           â”‚
â”‚  - /blackbox-targets             (EXISTENTE - backup)           â”‚
â”‚                                                                  â”‚
â”‚  Features:                                                       â”‚
â”‚  - Colunas 100% dinÃ¢micas via useMetadataFields(context)        â”‚
â”‚  - Filtros 100% dinÃ¢micos via useFilterFields(context)          â”‚
â”‚  - FormulÃ¡rios 100% dinÃ¢micos via useFormFields(context)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                            â†“ (PromQL)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROMETHEUS SERVERS                            â”‚
â”‚                                                                  â”‚
â”‚  - Palmas: 172.16.1.26:9090                                     â”‚
â”‚  - Rio: 172.16.200.14:9090                                      â”‚
â”‚  - DTC: 11.144.0.21:9090                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.2 Fluxo de Dados Completo

#### Fluxo 1: ExtraÃ§Ã£o de Tipos (Backend Startup)

```
1. Backend inicia â†’ app.py
2. Lifespan startup hook executa
3. Chama _prewarm_metadata_fields_cache()
4. Multi-config manager extrai prometheus.yml via SSH
5. monitoring_types_dynamic.extract_types_from_prometheus_jobs()
6. Categoriza cada job usando _infer_category_and_type()
7. Salva resultado no KV: skills/eye/monitoring-types/cache.json
8. Cache vÃ¡lido por 5 minutos
```

#### Fluxo 2: RequisiÃ§Ã£o de PÃ¡gina (Frontend)

```
1. UsuÃ¡rio acessa /monitoring/network-probes
2. React Router renderiza <DynamicMonitoringPage category="network-probes" />
3. Component chama useTableFields('network-probes')
4. Hook busca: GET /api/v1/metadata-fields/fields
5. Filtra campos onde show_in_network_probes !== false
6. Component chama: GET /api/v1/monitoring/data?category=network-probes
7. Backend lÃª cache KV de tipos
8. Filtra apenas tipos da categoria network-probes
9. Para cada tipo, executa query PromQL no Prometheus
10. Retorna dados agregados para o frontend
11. ProTable renderiza colunas dinamicamente
```

#### Fluxo 3: SincronizaÃ§Ã£o Manual (BotÃ£o no Frontend)

```
1. UsuÃ¡rio clica "Sincronizar Tipos"
2. Frontend chama: POST /api/v1/monitoring-types-dynamic/sync-cache
3. Backend forÃ§a extraÃ§Ã£o nova do Prometheus via SSH
4. Invalida cache existente
5. Salva novos tipos no KV
6. Retorna status de sucesso
7. Frontend recarrega dados
```

---

## ğŸ“¦ COMPONENTES A CRIAR

### 5.1 Backend Python

#### 5.1.1 ConsulKVConfigManager (NOVO)

**Arquivo:** `backend/core/consul_kv_config_manager.py`

**PropÃ³sito:** Gerenciador centralizado de configuraÃ§Ãµes no KV com cache inteligente

**Funcionalidades:**
- Cache em memÃ³ria com TTL configurÃ¡vel
- MÃ©todos get/put/delete com validaÃ§Ã£o Pydantic
- Namespace automÃ¡tico para keys (skills/eye/)
- InvalidaÃ§Ã£o de cache seletiva

**ImplementaÃ§Ã£o completa:**

```python
"""
Consul KV Config Manager - Gerenciador Central de ConfiguraÃ§Ãµes

RESPONSABILIDADES:
- Centralizar acesso ao Consul KV
- Cache inteligente com TTL
- ValidaÃ§Ã£o de dados com Pydantic
- Namespace automÃ¡tico (skills/eye/)
"""

from typing import Optional, Dict, Any, TypeVar, Type
from datetime import datetime, timedelta
from pydantic import BaseModel
import logging
import json

from core.kv_manager import KVManager

logger = logging.getLogger(__name__)

T = TypeVar('T', bound=BaseModel)


class CachedValue:
    """Valor com timestamp para cache"""
    def __init__(self, value: Any, ttl_seconds: int):
        self.value = value
        self.timestamp = datetime.now()
        self.ttl_seconds = ttl_seconds
    
    def is_expired(self) -> bool:
        age = datetime.now() - self.timestamp
        return age.total_seconds() > self.ttl_seconds


class ConsulKVConfigManager:
    """
    Gerenciador centralizado de configuraÃ§Ãµes no Consul KV
    
    Features:
    - Cache em memÃ³ria com TTL configurÃ¡vel
    - ValidaÃ§Ã£o automÃ¡tica com Pydantic
    - Namespace automÃ¡tico
    - InvalidaÃ§Ã£o de cache seletiva
    
    Exemplo:
        manager = ConsulKVConfigManager(ttl=300)  # 5 minutos
        
        # Salvar config
        await manager.put('monitoring-types/cache', types_data)
        
        # Ler config com cache
        data = await manager.get('monitoring-types/cache')
        
        # Invalidar cache
        manager.invalidate('monitoring-types/cache')
    """
    
    def __init__(self, prefix: str = "skills/eye/", ttl_seconds: int = 300):
        self.prefix = prefix
        self.ttl_seconds = ttl_seconds
        self.kv_manager = KVManager()
        self._cache: Dict[str, CachedValue] = {}
    
    def _full_key(self, key: str) -> str:
        """Adiciona namespace ao key"""
        return f"{self.prefix}{key}"
    
    async def get(
        self, 
        key: str, 
        model: Optional[Type[T]] = None,
        use_cache: bool = True
    ) -> Optional[Any]:
        """
        Busca valor do KV com cache
        
        Args:
            key: Chave (sem namespace)
            model: Modelo Pydantic para validaÃ§Ã£o (opcional)
            use_cache: Se deve usar cache
        
        Returns:
            Valor parseado ou None se nÃ£o encontrado
        """
        full_key = self._full_key(key)
        
        # Tentar cache primeiro
        if use_cache and full_key in self._cache:
            cached = self._cache[full_key]
            if not cached.is_expired():
                logger.debug(f"[CACHE HIT] {key}")
                return cached.value
            else:
                logger.debug(f"[CACHE EXPIRED] {key}")
                del self._cache[full_key]
        
        # Cache miss - buscar do Consul
        logger.debug(f"[CACHE MISS] {key}")
        value = await self.kv_manager.get_json(full_key)
        
        if value is None:
            return None
        
        # Validar com Pydantic se model fornecido
        if model:
            try:
                value = model(**value)
            except Exception as e:
                logger.error(f"[VALIDATION ERROR] {key}: {e}")
                return None
        
        # Salvar no cache
        if use_cache:
            self._cache[full_key] = CachedValue(value, self.ttl_seconds)
        
        return value
    
    async def put(
        self, 
        key: str, 
        value: Any,
        invalidate_cache: bool = True
    ) -> bool:
        """
        Salva valor no KV
        
        Args:
            key: Chave (sem namespace)
            value: Valor (dict, list ou Pydantic model)
            invalidate_cache: Se deve invalidar cache
        
        Returns:
            True se salvou com sucesso
        """
        full_key = self._full_key(key)
        
        # Converter Pydantic model para dict
        if isinstance(value, BaseModel):
            value = value.dict()
        
        # Salvar no Consul
        success = await self.kv_manager.put_json(full_key, value)
        
        if success and invalidate_cache:
            self.invalidate(key)
        
        return success
    
    async def delete(self, key: str) -> bool:
        """Remove key do KV e invalida cache"""
        full_key = self._full_key(key)
        
        success = await self.kv_manager.delete(full_key)
        
        if success:
            self.invalidate(key)
        
        return success
    
    def invalidate(self, key: str) -> None:
        """Invalida cache de um key especÃ­fico"""
        full_key = self._full_key(key)
        if full_key in self._cache:
            del self._cache[full_key]
            logger.debug(f"[CACHE INVALIDATED] {key}")
    
    def invalidate_all(self) -> None:
        """Invalida todo o cache"""
        self._cache.clear()
        logger.info("[CACHE] Todos os itens invalidados")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Retorna estatÃ­sticas do cache"""
        total_items = len(self._cache)
        expired_items = sum(1 for v in self._cache.values() if v.is_expired())
        
        return {
            "total_items": total_items,
            "active_items": total_items - expired_items,
            "expired_items": expired_items,
            "ttl_seconds": self.ttl_seconds
        }
```

**Uso no cÃ³digo:**

```python
# Criar instÃ¢ncia global
config_manager = ConsulKVConfigManager(ttl=300)

# Usar nos endpoints
@router.get("/monitoring-types-dynamic/from-prometheus")
async def get_types():
    # Buscar do cache/KV
    cached = await config_manager.get('monitoring-types/cache')
    
    if cached:
        return cached
    
    # Extrair do Prometheus
    types = await extract_from_prometheus()
    
    # Salvar no KV
    await config_manager.put('monitoring-types/cache', types)
    
    return types
```

---

#### 5.1.2 CategorizationRuleEngine (NOVO)

**Arquivo:** `backend/core/categorization_rule_engine.py`

**PropÃ³sito:** Motor de regras para categorizaÃ§Ã£o automÃ¡tica baseado em JSON

**JSON de regras (KV):**

```json
{
  "version": "1.0.0",
  "rules": [
    {
      "id": "blackbox_icmp",
      "priority": 100,
      "category": "network-probes",
      "conditions": {
        "job_name_pattern": "^(icmp|ping).*",
        "metrics_path": "/probe",
        "module_pattern": "^(icmp|ping)$"
      }
    },
    {
      "id": "blackbox_tcp",
      "priority": 100,
      "category": "network-probes",
      "conditions": {
        "job_name_pattern": "^tcp.*",
        "metrics_path": "/probe",
        "module_pattern": "^tcp.*"
      }
    },
    {
      "id": "blackbox_http",
      "priority": 100,
      "category": "web-probes",
      "conditions": {
        "job_name_pattern": "^http.*",
        "metrics_path": "/probe"
      }
    },
    {
      "id": "node_exporter",
      "priority": 90,
      "category": "system-exporters",
      "conditions": {
        "job_name_pattern": "^(node|selfnode).*",
        "metrics_path": "/metrics"
      }
    },
    {
      "id": "mysql_exporter",
      "priority": 80,
      "category": "database-exporters",
      "conditions": {
        "job_name_pattern": "^mysql.*"
      }
    }
  ],
  "default_category": "custom-exporters"
}
```

**ImplementaÃ§Ã£o:**

```python
"""
Categorization Rule Engine - Motor de Regras Baseado em JSON

RESPONSABILIDADES:
- Carregar regras do Consul KV
- Aplicar regras em ordem de prioridade
- Categorizar jobs automaticamente
"""

import re
from typing import Dict, List, Optional, Any
import logging

logger = logging.getLogger(__name__)


class CategorizationRule:
    """Uma regra de categorizaÃ§Ã£o"""
    def __init__(self, rule_data: Dict):
        self.id = rule_data['id']
        self.priority = rule_data.get('priority', 50)
        self.category = rule_data['category']
        self.conditions = rule_data['conditions']
        
        # Pre-compilar regexes
        self._compiled_patterns = {}
        for key, pattern in self.conditions.items():
            if key.endswith('_pattern'):
                try:
                    self._compiled_patterns[key] = re.compile(pattern, re.IGNORECASE)
                except re.error as e:
                    logger.error(f"[RULE {self.id}] Regex invÃ¡lida em {key}: {e}")
    
    def matches(self, job_data: Dict) -> bool:
        """Verifica se job satisfaz todas as condiÃ§Ãµes (AND)"""
        job_name = job_data.get('job_name', '').lower()
        metrics_path = job_data.get('metrics_path', '/metrics')
        module = job_data.get('module', '')
        
        # Verificar job_name_pattern
        if 'job_name_pattern' in self.conditions:
            pattern = self._compiled_patterns.get('job_name_pattern')
            if pattern and not pattern.match(job_name):
                return False
        
        # Verificar metrics_path
        if 'metrics_path' in self.conditions:
            if metrics_path != self.conditions['metrics_path']:
                return False
        
        # Verificar module_pattern
        if 'module_pattern' in self.conditions:
            pattern = self._compiled_patterns.get('module_pattern')
            if pattern and not pattern.match(module):
                return False
        
        # Todas as condiÃ§Ãµes satisfeitas
        return True


class CategorizationRuleEngine:
    """
    Motor de regras para categorizaÃ§Ã£o de jobs Prometheus
    
    Features:
    - Carrega regras do Consul KV
    - Aplica regras em ordem de prioridade (maior primeiro)
    - Suporta regex patterns
    - Categoria padrÃ£o para jobs nÃ£o categorizados
    
    Exemplo:
        engine = CategorizationRuleEngine()
        await engine.load_rules()
        
        category = engine.categorize({
            'job_name': 'icmp',
            'metrics_path': '/probe',
            'module': 'icmp'
        })
        # Returns: 'network-probes'
    """
    
    def __init__(self, config_manager):
        self.config_manager = config_manager
        self.rules: List[CategorizationRule] = []
        self.default_category = 'custom-exporters'
    
    async def load_rules(self) -> bool:
        """
        Carrega regras do Consul KV
        
        Returns:
            True se carregou com sucesso
        """
        try:
            rules_data = await self.config_manager.get('monitoring-types/categorization/rules')
            
            if not rules_data:
                logger.warning("[RULES] Nenhuma regra encontrada no KV, usando fallback")
                return False
            
            # Criar objetos de regra
            self.rules = []
            for rule_data in rules_data.get('rules', []):
                rule = CategorizationRule(rule_data)
                self.rules.append(rule)
            
            # Ordenar por prioridade (maior primeiro)
            self.rules.sort(key=lambda r: r.priority, reverse=True)
            
            # Categoria padrÃ£o
            self.default_category = rules_data.get('default_category', 'custom-exporters')
            
            logger.info(f"[RULES] {len(self.rules)} regras carregadas")
            return True
            
        except Exception as e:
            logger.error(f"[RULES] Erro ao carregar regras: {e}")
            return False
    
    def categorize(self, job_data: Dict) -> str:
        """
        Categoriza um job baseado nas regras
        
        Args:
            job_data: {
                'job_name': 'icmp',
                'metrics_path': '/probe',
                'module': 'icmp'  # opcional
            }
        
        Returns:
            Categoria identificada ou default_category
        """
        # Aplicar regras em ordem de prioridade
        for rule in self.rules:
            if rule.matches(job_data):
                logger.debug(
                    f"[CATEGORIZE] '{job_data.get('job_name')}' â†’ "
                    f"'{rule.category}' (rule: {rule.id})"
                )
                return rule.category
        
        # Nenhuma regra aplicou - usar categoria padrÃ£o
        logger.debug(
            f"[CATEGORIZE] '{job_data.get('job_name')}' â†’ "
            f"'{self.default_category}' (default)"
        )
        return self.default_category
```

**Como usar no monitoring_types_dynamic.py:**

```python
# Criar engine global
rule_engine = CategorizationRuleEngine(config_manager)

# Carregar regras no startup
@app.on_event("startup")
async def load_categorization_rules():
    await rule_engine.load_rules()

# Usar no lugar da funÃ§Ã£o _infer_category_and_type()
def categorize_job(job_config: Dict) -> str:
    job_data = {
        'job_name': job_config.get('job_name'),
        'metrics_path': job_config.get('metrics_path', '/metrics'),
        'module': _extract_blackbox_module(job_config)
    }
    
    return rule_engine.categorize(job_data)
```

---

#### 5.1.3 DynamicQueryBuilder com Jinja2 (NOVO)

**Arquivo:** `backend/core/dynamic_query_builder.py`

**PropÃ³sito:** Construtor de queries PromQL usando templates Jinja2

**ImplementaÃ§Ã£o:**

```python
"""
Dynamic Query Builder - Construtor de Queries PromQL com Jinja2

RESPONSABILIDADES:
- Renderizar templates Jinja2 de queries PromQL
- Suportar variÃ¡veis dinÃ¢micas (modules, jobs, labels)
- Cache de templates compilados
- ValidaÃ§Ã£o de queries
"""

from jinja2 import Environment, Template, TemplateError
from typing import Dict, Any, Optional
import logging

logger = logging.getLogger(__name__)


class DynamicQueryBuilder:
    """
    Construtor de queries PromQL dinÃ¢micas usando Jinja2
    
    Features:
    - Templates reutilizÃ¡veis
    - VariÃ¡veis dinÃ¢micas
    - Cache de templates compilados
    - ValidaÃ§Ã£o de sintaxe
    
    Exemplo:
        builder = DynamicQueryBuilder()
        
        template = '''
        probe_success{
            job="blackbox",
            __param_module=~"{{ modules|join('|') }}"
            {% if site %},site="{{ site }}"{% endif %}
        }
        '''
        
        query = builder.build(template, {
            'modules': ['icmp', 'tcp'],
            'site': 'palmas'
        })
        
        # Resultado:
        # probe_success{job="blackbox",__param_module=~"icmp|tcp",site="palmas"}
    """
    
    def __init__(self):
        self.env = Environment(
            trim_blocks=True,
            lstrip_blocks=True,
            autoescape=False  # PromQL nÃ£o precisa de escape
        )
        self._template_cache: Dict[str, Template] = {}
    
    def build(self, template_str: str, params: Dict[str, Any]) -> str:
        """
        ConstrÃ³i query PromQL a partir de template
        
        Args:
            template_str: Template Jinja2
            params: ParÃ¢metros para substituiÃ§Ã£o
        
        Returns:
            Query PromQL renderizada
        
        Raises:
            TemplateError: Se template invÃ¡lido
        """
        try:
            # Buscar template no cache
            if template_str not in self._template_cache:
                self._template_cache[template_str] = self.env.from_string(template_str)
            
            template = self._template_cache[template_str]
            
            # Renderizar com parÃ¢metros
            query = template.render(**params)
            
            # Limpar espaÃ§os extras
            query = ' '.join(query.split())
            
            logger.debug(f"[QUERY BUILD] Template renderizado: {query[:100]}...")
            return query
            
        except TemplateError as e:
            logger.error(f"[QUERY BUILD ERROR] Template invÃ¡lido: {e}")
            raise
        except Exception as e:
            logger.error(f"[QUERY BUILD ERROR] Erro inesperado: {e}")
            raise
    
    def clear_cache(self) -> None:
        """Limpa cache de templates"""
        self._template_cache.clear()
        logger.info("[QUERY BUILDER] Cache de templates limpo")


# Templates predefinidos
QUERY_TEMPLATES = {
    "network_probe_success": """
        probe_success{
            job="blackbox",
            __param_module=~"{{ modules|join('|') }}"
            {% if company %},company="{{ company }}"{% endif %}
            {% if site %},site="{{ site }}"{% endif %}
        }
    """,
    
    "network_probe_duration": """
        probe_duration_seconds{
            job="blackbox",
            __param_module=~"{{ modules|join('|') }}"
            {% if company %},company="{{ company }}"{% endif %}
        }
    """,
    
    "node_cpu_usage": """
        100 - (avg by (instance) (
            rate(node_cpu_seconds_total{
                job=~"{{ jobs|join('|') }}",
                mode="idle"
            }[{{ time_range|default("5m") }}])
        ) * 100)
    """,
    
    "node_memory_usage": """
        (1 - (
            node_memory_MemAvailable_bytes{job=~"{{ jobs|join('|') }}"} / 
            node_memory_MemTotal_bytes{job=~"{{ jobs|join('|') }}"}
        )) * 100
    """
}
```

**Uso:**

```python
# Criar builder
query_builder = DynamicQueryBuilder()

# Construir query para network probes
query = query_builder.build(
    QUERY_TEMPLATES['network_probe_success'],
    {
        'modules': ['icmp', 'tcp'],
        'company': 'Empresa Ramada',
        'site': 'palmas'
    }
)

# Executar query no Prometheus
response = requests.get(
    f"{prometheus_url}/api/v1/query",
    params={'query': query}
)
```

---

#### 5.1.4 Endpoint Unificado `/monitoring/data` (NOVO)

**Arquivo:** `backend/api/monitoring_unified.py`

**PropÃ³sito:** Endpoint Ãºnico que serve dados para todas as 4 pÃ¡ginas de monitoramento

**ImplementaÃ§Ã£o:**

```python
"""
API Unificada de Monitoramento - Endpoint Ãšnico para Todas as PÃ¡ginas

RESPONSABILIDADES:
- Endpoint unificado GET /api/v1/monitoring/data
- Filtra por categoria (network-probes, web-probes, etc)
- Executa queries PromQL dinamicamente
- Retorna dados formatados para ProTable
"""

from fastapi import APIRouter, HTTPException, Query
from typing import Optional, List, Dict, Any
import logging
import httpx

from core.consul_kv_config_manager import ConsulKVConfigManager
from core.dynamic_query_builder import DynamicQueryBuilder, QUERY_TEMPLATES
from core.multi_config_manager import MultiConfigManager

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/monitoring", tags=["Monitoring Unified"])

# Inicializar componentes
config_manager = ConsulKVConfigManager()
query_builder = DynamicQueryBuilder()
multi_config = MultiConfigManager()


@router.get("/data")
async def get_monitoring_data(
    category: str = Query(..., description="Categoria: network-probes, web-probes, etc"),
    server: Optional[str] = Query(None, description="Servidor Prometheus (opcional)"),
    company: Optional[str] = Query(None, description="Filtrar por empresa"),
    site: Optional[str] = Query(None, description="Filtrar por site")
):
    """
    Endpoint unificado para dados de monitoramento
    
    Este endpoint substitui mÃºltiplos endpoints especÃ­ficos.
    Funciona com QUALQUER categoria de monitoramento.
    
    Args:
        category: Categoria de monitoramento (ex: network-probes)
        server: Servidor Prometheus especÃ­fico (opcional)
        company: Filtro de empresa (opcional)
        site: Filtro de site (opcional)
    
    Returns:
        {
            "success": true,
            "category": "network-probes",
            "data": [
                {
                    "id": "...",
                    "instance": "10.0.0.1",
                    "module": "icmp",
                    "status": 1,
                    "latency": 25.3,
                    "company": "Empresa Ramada",
                    "site": "palmas"
                }
            ],
            "total": 150,
            "query": "probe_success{...}"
        }
    
    Example:
        GET /api/v1/monitoring/data?category=network-probes&company=Ramada
        GET /api/v1/monitoring/data?category=system-exporters&site=palmas
    """
    try:
        logger.info(f"[UNIFIED API] Buscando dados para category={category}")
        
        # STEP 1: Buscar tipos de monitoramento do cache
        types_cache = await config_manager.get('monitoring-types/cache')
        
        if not types_cache:
            raise HTTPException(
                status_code=500,
                detail="Cache de tipos nÃ£o disponÃ­vel. Execute sync-cache primeiro."
            )
        
        # STEP 2: Filtrar tipos pela categoria solicitada
        category_types = []
        for category_data in types_cache.get('categories', []):
            if category_data['category'] == category:
                category_types = category_data['types']
                break
        
        if not category_types:
            raise HTTPException(
                status_code=404,
                detail=f"Categoria '{category}' nÃ£o encontrada"
            )
        
        # STEP 3: Determinar servidor Prometheus
        if server:
            prometheus_server = server
        else:
            # Usar primeiro servidor disponÃ­vel
            prometheus_server = list(types_cache['servers'].keys())[0]
        
        # STEP 4: Construir query PromQL baseado na categoria
        if category in ['network-probes', 'web-probes']:
            # Blackbox probes
            modules = [t['module'] for t in category_types if t.get('module')]
            
            query = query_builder.build(
                QUERY_TEMPLATES['network_probe_success'],
                {
                    'modules': modules,
                    'company': company,
                    'site': site
                }
            )
        
        elif category == 'system-exporters':
            # Node/Windows exporters
            jobs = [t['job_name'] for t in category_types]
            
            query = query_builder.build(
                QUERY_TEMPLATES['node_cpu_usage'],
                {
                    'jobs': jobs,
                    'time_range': '5m'
                }
            )
        
        else:
            # Outros exporters - query genÃ©rica
            jobs = [t['job_name'] for t in category_types]
            query = f"up{{job=~\"{'|'.join(jobs)}\"}}"
        
        # STEP 5: Executar query no Prometheus
        prometheus_url = f"http://{prometheus_server}:9090"
        
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{prometheus_url}/api/v1/query",
                params={'query': query},
                timeout=10.0
            )
            response.raise_for_status()
            prom_data = response.json()
        
        # STEP 6: Processar resultados
        if prom_data['status'] != 'success':
            raise HTTPException(
                status_code=500,
                detail=f"Prometheus query failed: {prom_data.get('error')}"
            )
        
        results = prom_data['data']['result']
        
        # Formatar dados para ProTable
        formatted_data = []
        for result in results:
            metric = result['metric']
            value = result['value'][1]  # [timestamp, value]
            
            formatted_data.append({
                'id': f"{metric.get('instance', 'unknown')}_{metric.get('job', 'unknown')}",
                'instance': metric.get('instance', ''),
                'job': metric.get('job', ''),
                'module': metric.get('__param_module', ''),
                'status': float(value),
                'company': metric.get('company', ''),
                'site': metric.get('site', ''),
                **{k: v for k, v in metric.items() if not k.startswith('__')}
            })
        
        return {
            "success": True,
            "category": category,
            "data": formatted_data,
            "total": len(formatted_data),
            "query": query,
            "prometheus_server": prometheus_server
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[UNIFIED API ERROR] {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sync-cache")
async def sync_monitoring_cache():
    """
    ForÃ§a sincronizaÃ§Ã£o do cache de tipos de monitoramento
    
    Este endpoint:
    1. Extrai tipos de TODOS os servidores Prometheus via SSH
    2. Invalida cache existente
    3. Salva novos tipos no KV
    4. Retorna status
    
    Returns:
        {
            "success": true,
            "message": "Cache sincronizado com sucesso",
            "total_types": 45,
            "total_servers": 3
        }
    """
    try:
        logger.info("[SYNC CACHE] Iniciando sincronizaÃ§Ã£o forÃ§ada...")
        
        # Importar funÃ§Ã£o de extraÃ§Ã£o
        from api.monitoring_types_dynamic import extract_types_from_all_servers
        
        # Extrair tipos de todos os servidores
        result = await extract_types_from_all_servers()
        
        # Adicionar timestamp
        result['last_updated'] = datetime.now().isoformat()
        result['version'] = '1.0.0'
        
        # Salvar no KV (invalidando cache)
        await config_manager.put('monitoring-types/cache', result)
        
        logger.info(f"[SYNC CACHE] âœ“ Sincronizado: {result['total_types']} tipos")
        
        return {
            "success": True,
            "message": "Cache sincronizado com sucesso",
            "total_types": result['total_types'],
            "total_servers": result['total_servers']
        }
    
    except Exception as e:
        logger.error(f"[SYNC CACHE ERROR] {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
```

---

### 5.2 Frontend React

#### 5.2.1 DynamicMonitoringPage (NOVO)

**Arquivo:** `frontend/src/pages/DynamicMonitoringPage.tsx`

**PropÃ³sito:** Componente base Ãºnico para todas as 4 pÃ¡ginas de monitoramento

**ImplementaÃ§Ã£o completa:**

```typescript
/**
 * Dynamic Monitoring Page - Componente Base Ãšnico
 * 
 * Este componente renderiza QUALQUER pÃ¡gina de monitoramento de forma 100% dinÃ¢mica.
 * Funciona para network-probes, web-probes, system-exporters, database-exporters, etc.
 * 
 * CARACTERÃSTICAS:
 * - Colunas 100% dinÃ¢micas via useMetadataFields(category)
 * - Filtros 100% dinÃ¢micos via useFilterFields(category)
 * - Dados do endpoint /api/v1/monitoring/data?category={category}
 * - Reutiliza componentes: MetadataFilterBar, AdvancedSearchPanel, ColumnSelector
 * 
 * USO:
 *   <DynamicMonitoringPage category="network-probes" />
 *   <DynamicMonitoringPage category="web-probes" />
 */

import React, { useRef, useMemo, useCallback, useState, useEffect } from 'react';
import {
  Button,
  Space,
  Tooltip,
  message,
  Popconfirm,
  Tag
} from 'antd';
import {
  ReloadOutlined,
  SyncOutlined,
  FilterOutlined,
  ClearOutlined,
  DownloadOutlined
} from '@ant-design/icons';
import type { ActionType } from '@ant-design/pro-components';
import {
  PageContainer,
  ProTable,
} from '@ant-design/pro-components';

import { consulAPI } from '../services/api';
import { useTableFields, useFilterFields } from '../hooks/useMetadataFields';
import ColumnSelector, { type ColumnConfig } from '../components/ColumnSelector';
import MetadataFilterBar from '../components/MetadataFilterBar';
import AdvancedSearchPanel, { type SearchCondition } from '../components/AdvancedSearchPanel';
import ResizableTitle from '../components/ResizableTitle';

// MAPA DE TÃTULOS AMIGÃVEIS
const CATEGORY_DISPLAY_NAMES: Record<string, string> = {
  'network-probes': 'Network Probes (Rede)',
  'web-probes': 'Web Probes (AplicaÃ§Ãµes)',
  'system-exporters': 'Exporters: Sistemas',
  'database-exporters': 'Exporters: Bancos de Dados'
};

interface DynamicMonitoringPageProps {
  category: string;  // 'network-probes', 'web-probes', etc
}

interface MonitoringDataItem {
  id: string;
  instance: string;
  job: string;
  status: number;
  [key: string]: any;  // Campos dinÃ¢micos
}

type MonitoringColumn = import('@ant-design/pro-components').ProColumns<MonitoringDataItem>;

const DynamicMonitoringPage: React.FC<DynamicMonitoringPageProps> = ({ category }) => {
  const actionRef = useRef<ActionType | null>(null);
  
  // SISTEMA DINÃ‚MICO: Carregar campos metadata para esta categoria
  const { tableFields, loading: tableFieldsLoading } = useTableFields(category);
  const { filterFields, loading: filterFieldsLoading } = useFilterFields(category);
  
  // Estados
  const [filters, setFilters] = useState<Record<string, string | undefined>>({});
  const [columnConfig, setColumnConfig] = useState<ColumnConfig[]>([]);
  const [columnWidths, setColumnWidths] = useState<Record<string, number>>({});
  const [advancedOpen, setAdvancedOpen] = useState(false);
  const [advancedConditions, setAdvancedConditions] = useState<SearchCondition[]>([]);
  const [advancedOperator, setAdvancedOperator] = useState<'and' | 'or'>('and');
  const [syncLoading, setSyncLoading] = useState(false);
  
  // SISTEMA DINÃ‚MICO: Combinar colunas fixas + campos metadata
  const defaultColumnConfig = useMemo<ColumnConfig[]>(() => {
    const metadataColumns: ColumnConfig[] = tableFields.map((field) => ({
      key: field.name,
      title: field.display_name,
      visible: field.show_in_table ?? true,
      locked: false
    }));
    
    // Colunas fixas que sempre existem
    const fixedColumns: ColumnConfig[] = [
      { key: 'instance', title: 'Instance', visible: true },
      { key: 'job', title: 'Job', visible: true },
      { key: 'status', title: 'Status', visible: true },
      { key: 'actions', title: 'AÃ§Ãµes', visible: true, locked: true }
    ];
    
    return [...fixedColumns, ...metadataColumns];
  }, [tableFields]);
  
  // Atualizar columnConfig quando tableFields carregar
  useEffect(() => {
    if (defaultColumnConfig.length > 0 && columnConfig.length === 0) {
      setColumnConfig(defaultColumnConfig);
    }
  }, [defaultColumnConfig, columnConfig.length]);
  
  // SISTEMA DINÃ‚MICO: Gerar colunas do ProTable
  const proTableColumns = useMemo<MonitoringColumn[]>(() => {
    const visibleConfigs = columnConfig.filter(c => c.visible);
    
    return visibleConfigs.map((colConfig) => {
      const baseColumn: MonitoringColumn = {
        title: () => (
          <ResizableTitle
            title={colConfig.title}
            width={columnWidths[colConfig.key] || 150}
            onResize={(width) => {
              setColumnWidths(prev => ({ ...prev, [colConfig.key]: width }));
            }}
          />
        ),
        dataIndex: colConfig.key,
        key: colConfig.key,
        width: columnWidths[colConfig.key] || 150,
        fixed: colConfig.locked ? 'left' : undefined,
        ellipsis: true,
      };
      
      // RenderizaÃ§Ã£o especial para status
      if (colConfig.key === 'status') {
        baseColumn.render = (value: number) => (
          <Tag color={value === 1 ? 'success' : 'error'}>
            {value === 1 ? 'Online' : 'Offline'}
          </Tag>
        );
      }
      
      // RenderizaÃ§Ã£o especial para actions
      if (colConfig.key === 'actions') {
        baseColumn.render = (_, record) => (
          <Space>
            <Tooltip title="Ver detalhes">
              <Button
                type="link"
                size="small"
                onClick={() => {
                  message.info(`Detalhes de ${record.instance}`);
                }}
              >
                Detalhes
              </Button>
            </Tooltip>
          </Space>
        );
      }
      
      return baseColumn;
    });
  }, [columnConfig, columnWidths]);
  
  // Request handler - busca dados do backend
  const requestHandler = useCallback(async (params: any) => {
    try {
      // Construir query params
      const queryParams = new URLSearchParams({
        category,
        ...filters
      });
      
      const response = await fetch(`/api/v1/monitoring/data?${queryParams}`);
      const data = await response.json();
      
      if (!data.success) {
        throw new Error(data.detail || 'Erro ao buscar dados');
      }
      
      return {
        data: data.data || [],
        success: true,
        total: data.total || 0
      };
    } catch (error) {
      message.error('Erro ao carregar dados: ' + error);
      return {
        data: [],
        success: false,
        total: 0
      };
    }
  }, [category, filters]);
  
  // Handler de sincronizaÃ§Ã£o
  const handleSync = useCallback(async () => {
    setSyncLoading(true);
    try {
      const response = await fetch('/api/v1/monitoring/sync-cache', {
        method: 'POST'
      });
      
      const data = await response.json();
      
      if (data.success) {
        message.success('Cache sincronizado com sucesso!');
        actionRef.current?.reload();
      } else {
        throw new Error(data.detail || 'Erro ao sincronizar');
      }
    } catch (error) {
      message.error('Erro ao sincronizar: ' + error);
    } finally {
      setSyncLoading(false);
    }
  }, []);
  
  // Aplicar filtros avanÃ§ados
  const applyAdvancedFilters = useCallback(
    (data: MonitoringDataItem[]) => {
      if (!advancedConditions.length) {
        return data;
      }
      
      return data.filter((row) => {
        const evaluations = advancedConditions.map((condition) => {
          const value = row[condition.field];
          const target = condition.value;
          
          switch (condition.operator) {
            case 'eq':
              return value === target;
            case 'ne':
              return value !== target;
            case 'contains':
              return String(value).includes(String(target));
            default:
              return true;
          }
        });
        
        return advancedOperator === 'and'
          ? evaluations.every(Boolean)
          : evaluations.some(Boolean);
      });
    },
    [advancedConditions, advancedOperator]
  );
  
  return (
    <PageContainer
      title={CATEGORY_DISPLAY_NAMES[category] || category}
      extra={[
        <Button
          key="sync"
          icon={<SyncOutlined spin={syncLoading} />}
          onClick={handleSync}
          loading={syncLoading}
        >
          Sincronizar Cache
        </Button>,
        <Button
          key="advanced"
          icon={<FilterOutlined />}
          onClick={() => setAdvancedOpen(true)}
        >
          Filtro AvanÃ§ado
        </Button>,
        <ColumnSelector
          key="columns"
          columns={columnConfig}
          onChange={setColumnConfig}
        />
      ]}
    >
      {/* Barra de filtros metadata */}
      <MetadataFilterBar
        fields={filterFields}
        filters={filters}
        onChange={(newFilters) => {
          setFilters(newFilters);
          actionRef.current?.reload();
        }}
      />
      
      {/* Tabela principal */}
      <ProTable<MonitoringDataItem>
        actionRef={actionRef}
        rowKey="id"
        columns={proTableColumns}
        request={requestHandler}
        pagination={{
          defaultPageSize: 20,
          showSizeChanger: true,
        }}
        search={false}
        options={{
          reload: true,
          setting: false,
          density: true,
        }}
        toolbar={{
          actions: [
            <Button
              key="clear"
              icon={<ClearOutlined />}
              onClick={() => {
                setFilters({});
                actionRef.current?.reload();
              }}
            >
              Limpar Filtros
            </Button>
          ]
        }}
      />
      
      {/* Painel de busca avanÃ§ada */}
      <AdvancedSearchPanel
        visible={advancedOpen}
        onClose={() => setAdvancedOpen(false)}
        fields={tableFields.map(f => ({ name: f.name, label: f.display_name }))}
        conditions={advancedConditions}
        operator={advancedOperator}
        onConditionsChange={setAdvancedConditions}
        onOperatorChange={setAdvancedOperator}
        onApply={() => {
          setAdvancedOpen(false);
          actionRef.current?.reload();
        }}
      />
    </PageContainer>
  );
};

export default DynamicMonitoringPage;
```

---

#### 5.2.2 Rotas DinÃ¢micas (ATUALIZAR)

**Arquivo:** `frontend/src/routes.tsx`

**Adicionar rotas para as 4 novas pÃ¡ginas:**

```typescript
import { lazy } from 'react';
import DynamicMonitoringPage from '@/pages/DynamicMonitoringPage';

// PÃ¡ginas existentes (backup/referÃªncia)
const Services = lazy(() => import('@/pages/Services'));
const BlackboxTargets = lazy(() => import('@/pages/BlackboxTargets'));

// NOVAS PÃGINAS - todas usam DynamicMonitoringPage
const NetworkProbes = () => <DynamicMonitoringPage category="network-probes" />;
const WebProbes = () => <DynamicMonitoringPage category="web-probes" />;
const SystemExporters = () => <DynamicMonitoringPage category="system-exporters" />;
const DatabaseExporters = () => <DynamicMonitoringPage category="database-exporters" />;

export const routes = [
  // ... rotas existentes ...
  
  // BACKUP/REFERÃŠNCIA - pÃ¡ginas antigas
  {
    path: '/services',
    component: Services,
    name: 'Services (Backup)',
  },
  {
    path: '/blackbox-targets',
    component: BlackboxTargets,
    name: 'Blackbox Targets (Backup)',
  },
  
  // NOVAS PÃGINAS DINÃ‚MICAS
  {
    path: '/monitoring/network-probes',
    component: NetworkProbes,
    name: 'Network Probes',
    icon: 'WifiOutlined',
  },
  {
    path: '/monitoring/web-probes',
    component: WebProbes,
    name: 'Web Probes',
    icon: 'GlobalOutlined',
  },
  {
    path: '/monitoring/system-exporters',
    component: SystemExporters,
    name: 'System Exporters',
    icon: 'DesktopOutlined',
  },
  {
    path: '/monitoring/database-exporters',
    component: DatabaseExporters,
    name: 'Database Exporters',
    icon: 'DatabaseOutlined',
  },
];
```

---

#### 5.2.3 Hook useMetadataFields Melhorado (ATUALIZAR)

**Arquivo:** `frontend/src/hooks/useMetadataFields.ts`

**Modificar para aceitar contexto dinÃ¢mico:**

```typescript
/**
 * Hook useTableFields - VersÃ£o 2.0 (100% DinÃ¢mica)
 * 
 * Aceita QUALQUER contexto como string e filtra campos automaticamente.
 * NÃ£o precisa mais hardcodar contextos como 'services' ou 'blackbox'.
 * 
 * USO:
 *   useTableFields('services')             // Funciona
 *   useTableFields('network-probes')       // Funciona
 *   useTableFields('custom-exporters')     // Funciona
 *   useTableFields('qualquer-categoria')   // Funciona
 */

import { useState, useEffect } from 'react';
import type { MetadataField } from '../services/api';

// Cache global (5 minutos)
const CACHE_TTL = 5 * 60 * 1000;
let cachedFields: MetadataField[] | null = null;
let cacheTimestamp: number = 0;

export function useTableFields(context: string) {
  const [fields, setFields] = useState<MetadataField[]>([]);
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    async function loadFields() {
      setLoading(true);
      
      try {
        // Verificar cache
        const now = Date.now();
        if (cachedFields && (now - cacheTimestamp) < CACHE_TTL) {
          console.log('[useMetadataFields] Cache HIT');
          filterAndSetFields(cachedFields, context);
          setLoading(false);
          return;
        }
        
        // Cache miss - buscar do backend
        console.log('[useMetadataFields] Cache MISS - buscando do backend');
        const response = await fetch('/api/v1/metadata-fields/fields');
        const data = await response.json();
        
        if (!data.success || !data.fields) {
          throw new Error('Resposta invÃ¡lida do backend');
        }
        
        // Atualizar cache global
        cachedFields = data.fields;
        cacheTimestamp = now;
        
        // Filtrar e setar campos
        filterAndSetFields(cachedFields, context);
        
      } catch (error) {
        console.error('[useMetadataFields] Erro ao carregar campos:', error);
        setFields([]);
      } finally {
        setLoading(false);
      }
    }
    
    function filterAndSetFields(allFields: MetadataField[], context: string) {
      // Construir chave de filtro: show_in_{context}
      // Exemplo: 'network-probes' â†’ 'show_in_network_probes'
      const showInKey = `show_in_${context.replace(/-/g, '_')}`;
      
      console.log(`[useMetadataFields] Filtrando campos para context="${context}" (${showInKey})`);
      
      const filtered = allFields.filter((field) => {
        // Se campo nÃ£o tem a propriedade show_in_{context}, exibe por padrÃ£o
        if (!(showInKey in field)) {
          return true;
        }
        
        // Se tem a propriedade, respeitar o valor
        return field[showInKey] !== false;
      });
      
      console.log(`[useMetadataFields] ${filtered.length}/${allFields.length} campos visÃ­veis`);
      setFields(filtered);
    }
    
    loadFields();
  }, [context]);
  
  return { tableFields: fields, loading };
}

// Hooks similares para form e filter
export function useFormFields(context: string) {
  const { tableFields, loading } = useTableFields(context);
  
  const formFields = tableFields.filter(field => {
    const showInKey = `show_in_${context.replace(/-/g, '_')}_form`;
    if (!(showInKey in field)) {
      return field.show_in_form !== false;  // Fallback para propriedade genÃ©rica
    }
    return field[showInKey] !== false;
  });
  
  return { formFields, loading };
}

export function useFilterFields(context: string) {
  const { tableFields, loading } = useTableFields(context);
  
  const filterFields = tableFields.filter(field => {
    return field.show_in_filter !== false;
  });
  
  return { filterFields, loading };
}
```

---

## ğŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO DETALHADO

### FASE 1: PreparaÃ§Ã£o (Dias 1-2)

#### Dia 1: AnÃ¡lise e Setup

**MANHÃƒ:**
1. âœ… **Revisar documento completo** - garantir entendimento total
2. âœ… **Criar branch Git** - `feature/dynamic-monitoring-pages`
3. âœ… **Backup das pÃ¡ginas existentes** - Services.tsx e BlackboxTargets.tsx
4. âœ… **Setup ambiente de desenvolvimento** - backend + frontend rodando

**Checklist:**
```bash
# Backend
cd backend
source venv/bin/activate
python app.py  # Deve iniciar em http://localhost:5000

# Frontend (outro terminal)
cd frontend
npm run dev  # Deve iniciar em http://localhost:8081

# Git
git checkout -b feature/dynamic-monitoring-pages
git status
```

**TARDE:**
5. âœ… **Criar estrutura de arquivos vazios**
   ```bash
   # Backend
   touch backend/core/consul_kv_config_manager.py
   touch backend/core/categorization_rule_engine.py
   touch backend/core/dynamic_query_builder.py
   touch backend/api/monitoring_unified.py
   
   # Frontend
   touch frontend/src/pages/DynamicMonitoringPage.tsx
   ```

6. âœ… **Configurar JSON de regras no KV**
   ```bash
   # Criar arquivo local
   cat > categorization_rules.json << 'EOF'
   {
     "version": "1.0.0",
     "rules": [...],  # Usar JSON completo da seÃ§Ã£o 5.1.2
     "default_category": "custom-exporters"
   }
   EOF
   
   # Upload para Consul
   curl -X PUT \
     -H "X-Consul-Token: $CONSUL_TOKEN" \
     --data-binary @categorization_rules.json \
     "http://172.16.1.26:8500/v1/kv/skills/eye/monitoring-types/categorization/rules"
   ```

#### Dia 2: ValidaÃ§Ã£o de Prerequisitos

**MANHÃƒ:**
7. âœ… **Testar endpoint monitoring_types_dynamic existente**
   ```bash
   curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL" | jq
   
   # Validar resposta:
   # - success: true
   # - categories[]: deve ter 8 categorias
   # - all_types[]: deve ter 15+ tipos
   ```

8. âœ… **Testar metadata fields existente**
   ```bash
   curl "http://localhost:5000/api/v1/metadata-fields/fields" | jq
   
   # Validar resposta:
   # - success: true
   # - fields[]: deve ter 22 campos
   # - cada campo tem: name, display_name, show_in_services, show_in_blackbox
   ```

**TARDE:**
9. âœ… **Validar hooks React existentes**
   - Abrir DevTools no navegador
   - Ir em /services
   - Verificar no Network tab: GET /api/v1/metadata-fields/fields
   - Confirmar que useMetadataFields estÃ¡ funcionando

10. âœ… **Criar documento de progresso**
    ```bash
    cat > IMPLEMENTACAO_PROGRESSO.md << 'EOF'
    # Progresso da ImplementaÃ§Ã£o
    
    ## Fase 1: PreparaÃ§Ã£o
    - [ ] Dia 1: Setup e estrutura
    - [ ] Dia 2: ValidaÃ§Ã£o
    
    ## Fase 2: Backend
    - [ ] Dia 3-4: Core components
    - [ ] Dia 5: API endpoints
    
    ## Fase 3: Frontend
    - [ ] Dia 6-7: DynamicMonitoringPage
    - [ ] Dia 8: Rotas e integraÃ§Ã£o
    
    ## Fase 4: Testes
    - [ ] Dia 9-10: Testes completos
    EOF
    ```

---

### FASE 2: Backend (Dias 3-5)

#### Dia 3: Core Components Parte 1

**MANHÃƒ: ConsulKVConfigManager**

1. âœ… **Implementar ConsulKVConfigManager**
   - Copiar cÃ³digo completo da seÃ§Ã£o 5.1.1
   - Arquivo: `backend/core/consul_kv_config_manager.py`

2. âœ… **Criar testes unitÃ¡rios**
   ```python
   # backend/tests/test_consul_kv_config_manager.py
   import pytest
   from core.consul_kv_config_manager import ConsulKVConfigManager
   
   @pytest.mark.asyncio
   async def test_get_put():
       manager = ConsulKVConfigManager(ttl=10)
       
       # Salvar
       data = {"test": "value"}
       result = await manager.put('test/key', data)
       assert result == True
       
       # Buscar (deve vir do KV)
       retrieved = await manager.get('test/key')
       assert retrieved == data
       
       # Buscar novamente (deve vir do cache)
       retrieved2 = await manager.get('test/key')
       assert retrieved2 == data
       
       # Verificar cache
       stats = manager.get_cache_stats()
       assert stats['active_items'] == 1
   
   @pytest.mark.asyncio
   async def test_cache_expiration():
       manager = ConsulKVConfigManager(ttl=1)  # 1 segundo
       
       await manager.put('test/expire', {"data": "test"})
       
       # Deve estar no cache
       value1 = await manager.get('test/expire')
       assert value1 is not None
       
       # Aguardar expiraÃ§Ã£o
       await asyncio.sleep(2)
       
       # Deve buscar do KV novamente
       value2 = await manager.get('test/expire')
       assert value2 is not None
   ```

3. âœ… **Executar testes**
   ```bash
   cd backend
   pytest tests/test_consul_kv_config_manager.py -v
   
   # Deve passar todos os testes
   ```

**TARDE: DynamicQueryBuilder**

4. âœ… **Implementar DynamicQueryBuilder**
   - Copiar cÃ³digo completo da seÃ§Ã£o 5.1.3
   - Arquivo: `backend/core/dynamic_query_builder.py`

5. âœ… **Criar testes unitÃ¡rios**
   ```python
   # backend/tests/test_dynamic_query_builder.py
   from core.dynamic_query_builder import DynamicQueryBuilder, QUERY_TEMPLATES
   
   def test_simple_query():
       builder = DynamicQueryBuilder()
       
       template = 'up{job="{{ job }}"}'
       query = builder.build(template, {'job': 'prometheus'})
       
       assert query == 'up{job="prometheus"}'
   
   def test_network_probe_query():
       builder = DynamicQueryBuilder()
       
       query = builder.build(
           QUERY_TEMPLATES['network_probe_success'],
           {
               'modules': ['icmp', 'tcp'],
               'company': 'Ramada',
               'site': 'palmas'
           }
       )
       
       # Verificar que query tem os elementos corretos
       assert 'icmp|tcp' in query
       assert 'company="Ramada"' in query
       assert 'site="palmas"' in query
   
   def test_optional_params():
       builder = DynamicQueryBuilder()
       
       # Sem site
       query = builder.build(
           QUERY_TEMPLATES['network_probe_success'],
           {
               'modules': ['icmp'],
               'company': 'Ramada'
           }
       )
       
       assert 'site=' not in query  # Site nÃ£o deve aparecer
   ```

6. âœ… **Executar testes**
   ```bash
   pytest tests/test_dynamic_query_builder.py -v
   ```

#### Dia 4: Core Components Parte 2

**MANHÃƒ: CategorizationRuleEngine**

7. âœ… **Implementar CategorizationRuleEngine**
   - Copiar cÃ³digo completo da seÃ§Ã£o 5.1.2
   - Arquivo: `backend/core/categorization_rule_engine.py`

8. âœ… **Criar testes unitÃ¡rios**
   ```python
   # backend/tests/test_categorization_rule_engine.py
   import pytest
   from core.categorization_rule_engine import CategorizationRuleEngine
   from core.consul_kv_config_manager import ConsulKVConfigManager
   
   @pytest.mark.asyncio
   async def test_load_rules():
       config_manager = ConsulKVConfigManager()
       engine = CategorizationRuleEngine(config_manager)
       
       # Carregar regras do KV
       success = await engine.load_rules()
       assert success == True
       assert len(engine.rules) > 0
   
   def test_categorize_icmp():
       # ... (setup engine com regras mockadas)
       
       category = engine.categorize({
           'job_name': 'icmp',
           'metrics_path': '/probe',
           'module': 'icmp'
       })
       
       assert category == 'network-probes'
   
   def test_categorize_http():
       # ...
       
       category = engine.categorize({
           'job_name': 'http_2xx',
           'metrics_path': '/probe',
           'module': 'http_2xx'
       })
       
       assert category == 'web-probes'
   
   def test_categorize_unknown():
       # ...
       
       category = engine.categorize({
           'job_name': 'custom_unknown_job',
           'metrics_path': '/metrics'
       })
       
       assert category == 'custom-exporters'  # Default
   ```

9. âœ… **Executar testes**
   ```bash
   pytest tests/test_categorization_rule_engine.py -v
   ```

**TARDE: IntegraÃ§Ã£o com monitoring_types_dynamic.py**

10. âœ… **Modificar monitoring_types_dynamic.py para usar RuleEngine**
    ```python
    # backend/api/monitoring_types_dynamic.py
    
    # ADICIONAR no topo do arquivo:
    from core.consul_kv_config_manager import ConsulKVConfigManager
    from core.categorization_rule_engine import CategorizationRuleEngine
    
    # Criar instÃ¢ncias globais
    config_manager = ConsulKVConfigManager()
    rule_engine = CategorizationRuleEngine(config_manager)
    
    # MODIFICAR funÃ§Ã£o extract_types_from_prometheus_jobs():
    async def extract_types_from_prometheus_jobs(...):
        # ... cÃ³digo existente ...
        
        for job in scrape_configs:
            job_name = job.get('job_name', 'unknown')
            
            # ... cÃ³digo existente ...
            
            # SUBSTITUIR chamada _infer_category_and_type() por:
            module = _extract_blackbox_module(job)
            
            category = rule_engine.categorize({
                'job_name': job_name,
                'metrics_path': job.get('metrics_path', '/metrics'),
                'module': module
            })
            
            # NOVA funÃ§Ã£o helper para display_name e exporter_type
            type_info = _get_type_info(job_name, category, module)
            
            type_schema = {
                "id": job_name,
                "display_name": type_info['display_name'],
                "category": category,
                "job_name": job_name,
                "exporter_type": type_info['exporter_type'],
                "module": module,
                "fields": fields,
                "metrics_path": job.get('metrics_path', '/metrics'),
                "server": server_host,
            }
            
            types.append(type_schema)
    
    def _get_type_info(job_name: str, category: str, module: Optional[str]) -> Dict:
        """
        Retorna display_name e exporter_type baseado no job_name
        
        Esta funÃ§Ã£o SUBSTITUI a lÃ³gica hardcoded de _infer_category_and_type()
        """
        # Para blackbox, usar formataÃ§Ã£o do mÃ³dulo
        if category in ['network-probes', 'web-probes']:
            return {
                'display_name': _format_display_name(module or job_name),
                'exporter_type': 'blackbox'
            }
        
        # Para outros exporters, inferir do job_name
        job_lower = job_name.lower()
        
        if 'node' in job_lower:
            return {'display_name': 'Node Exporter (Linux)', 'exporter_type': 'node_exporter'}
        elif 'windows' in job_lower:
            return {'display_name': 'Windows Exporter', 'exporter_type': 'windows_exporter'}
        elif 'mysql' in job_lower:
            return {'display_name': 'MySQL Exporter', 'exporter_type': 'mysql_exporter'}
        # ... etc (usar mesma lÃ³gica da funÃ§Ã£o original)
        else:
            # Custom exporter
            return {
                'display_name': job_name.replace('-', ' ').replace('_', ' ').title(),
                'exporter_type': 'custom'
            }
    ```

11. âœ… **Testar modificaÃ§Ã£o**
    ```bash
    # Reiniciar backend
    python app.py
    
    # Testar endpoint
    curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL" | jq
    
    # Validar que:
    # 1. Ainda retorna as mesmas categorias
    # 2. Tipos estÃ£o corretos
    # 3. NÃ£o hÃ¡ erros no log
    ```

#### Dia 5: Implementar Cache KV e Endpoint Unificado

**MANHÃƒ: Cache KV**

12. âœ… **Adicionar cache KV ao monitoring_types_dynamic.py**
    ```python
    # backend/api/monitoring_types_dynamic.py
    
    @router.get("/from-prometheus")
    async def get_types_from_prometheus(
        server: Optional[str] = Query(None),
        force_refresh: bool = Query(False, description="ForÃ§ar extraÃ§Ã£o do Prometheus")
    ):
        """
        Busca tipos de monitoramento com cache KV
        """
        try:
            cache_key = 'monitoring-types/cache'
            
            # Se nÃ£o forÃ§ou refresh, tentar buscar do cache
            if not force_refresh:
                cached = await config_manager.get(cache_key)
                
                if cached:
                    logger.info(f"[CACHE HIT] Usando tipos em cache")
                    
                    # Filtrar por servidor se necessÃ¡rio
                    if server and server != 'ALL':
                        # ... filtrar cached['servers'] ...
                        pass
                    
                    return cached
            
            # Cache miss ou force_refresh - extrair do Prometheus
            logger.info("[CACHE MISS] Extraindo tipos do Prometheus via SSH...")
            
            # ... cÃ³digo existente de extraÃ§Ã£o ...
            result = await extract_types_from_all_servers(server)
            
            # Adicionar metadata
            result['version'] = '1.0.0'
            result['last_updated'] = datetime.now().isoformat()
            result['ttl_seconds'] = 300
            
            # Salvar no cache
            await config_manager.put(cache_key, result)
            logger.info("[CACHE WRITE] Tipos salvos no KV")
            
            return result
            
        except Exception as e:
            logger.error(f"[ERROR] {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))
    ```

13. âœ… **Testar cache**
    ```bash
    # Primeira chamada (deve extrair do Prometheus)
    time curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL"
    # Tempo: ~2-3 segundos
    
    # Segunda chamada (deve vir do cache)
    time curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL"
    # Tempo: <100ms
    
    # ForÃ§ar refresh
    curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL&force_refresh=true"
    # Tempo: ~2-3 segundos novamente
    ```

**TARDE: Endpoint Unificado**

14. âœ… **Implementar monitoring_unified.py**
    - Copiar cÃ³digo completo da seÃ§Ã£o 5.1.4
    - Arquivo: `backend/api/monitoring_unified.py`

15. âœ… **Registrar router no app.py**
    ```python
    # backend/app.py
    
    # ADICIONAR import
    from api.monitoring_unified import router as monitoring_unified_router
    
    # ADICIONAR router
    app.include_router(monitoring_unified_router, prefix="/api/v1", tags=["Monitoring Unified"])
    ```

16. âœ… **Testar endpoint unificado**
    ```bash
    # Testar network-probes
    curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes" | jq
    
    # Testar web-probes
    curl "http://localhost:5000/api/v1/monitoring/data?category=web-probes" | jq
    
    # Testar system-exporters
    curl "http://localhost:5000/api/v1/monitoring/data?category=system-exporters" | jq
    
    # Validar que:
    # 1. success: true
    # 2. data[]: array com resultados
    # 3. query: query PromQL executada
    # 4. total: nÃºmero de itens
    ```

17. âœ… **Commit do backend**
    ```bash
    git add backend/
    git commit -m "feat(backend): Implementar componentes dinÃ¢micos e endpoint unificado

    - Adicionar ConsulKVConfigManager com cache TTL
    - Adicionar CategorizationRuleEngine baseado em JSON
    - Adicionar DynamicQueryBuilder com Jinja2
    - Modificar monitoring_types_dynamic para usar cache KV
    - Adicionar endpoint unificado /monitoring/data
    - Testes unitÃ¡rios completos

    BREAKING CHANGE: monitoring_types_dynamic agora usa cache KV"
    ```

---

### FASE 3: Frontend (Dias 6-8)

#### Dia 6: DynamicMonitoringPage Parte 1

**MANHÃƒ: Componente Base**

18. âœ… **Implementar DynamicMonitoringPage.tsx**
    - Copiar cÃ³digo completo da seÃ§Ã£o 5.2.1
    - Arquivo: `frontend/src/pages/DynamicMonitoringPage.tsx`

19. âœ… **Modificar useMetadataFields.ts**
    - Copiar cÃ³digo completo da seÃ§Ã£o 5.2.3
    - Arquivo: `frontend/src/hooks/useMetadataFields.ts`

20. âœ… **Testar componente isoladamente**
    - Criar arquivo temporÃ¡rio de teste:
    ```typescript
    // frontend/src/pages/TestDynamicPage.tsx
    import React from 'react';
    import DynamicMonitoringPage from './DynamicMonitoringPage';
    
    export default function TestDynamicPage() {
      return <DynamicMonitoringPage category="network-probes" />;
    }
    ```
    
    - Adicionar rota temporÃ¡ria em routes.tsx
    - Acessar http://localhost:8081/test-dynamic
    - Validar que pÃ¡gina carrega sem erros

**TARDE: Ajustes e Refinamentos**

21. âœ… **Adicionar tratamento de erros**
    - Adicionar ErrorBoundary
    - Adicionar mensagens de erro amigÃ¡veis
    - Adicionar loading states

22. âœ… **Adicionar funcionalidades extras**
    - Export para CSV
    - Refresh automÃ¡tico (opcional)
    - Contador de itens online/offline

23. âœ… **Testar responsividade**
    - Testar em diferentes tamanhos de tela
    - Validar que colunas se ajustam
    - Validar que filtros funcionam em mobile

#### Dia 7: IntegraÃ§Ã£o com Rotas

**MANHÃƒ: Rotas e Menu**

24. âœ… **Adicionar rotas em routes.tsx**
    - Copiar cÃ³digo da seÃ§Ã£o 5.2.2
    - Arquivo: `frontend/src/routes.tsx`

25. âœ… **Atualizar menu de navegaÃ§Ã£o**
    ```typescript
    // frontend/src/layouts/BasicLayout.tsx (ou equivalente)
    
    const menuItems = [
      // ... itens existentes ...
      
      // NOVO GRUPO: Monitoramento por Tipo
      {
        key: 'monitoring-group',
        label: 'Monitoramento por Tipo',
        icon: <DashboardOutlined />,
        children: [
          {
            key: '/monitoring/network-probes',
            label: 'Network Probes',
            icon: <WifiOutlined />,
          },
          {
            key: '/monitoring/web-probes',
            label: 'Web Probes',
            icon: <GlobalOutlined />,
          },
          {
            key: '/monitoring/system-exporters',
            label: 'System Exporters',
            icon: <DesktopOutlined />,
          },
          {
            key: '/monitoring/database-exporters',
            label: 'Database Exporters',
            icon: <DatabaseOutlined />,
          },
        ]
      },
      
      // Grupo de backup (opcional, escondido por padrÃ£o)
      {
        key: 'backup-group',
        label: 'PÃ¡ginas Legacy (Backup)',
        icon: <FileOutlined />,
        children: [
          {
            key: '/services',
            label: 'Services (Antigo)',
          },
          {
            key: '/blackbox-targets',
            label: 'Blackbox Targets (Antigo)',
          },
        ]
      }
    ];
    ```

**TARDE: Testes de NavegaÃ§Ã£o**

26. âœ… **Testar todas as rotas**
    ```
    âœ“ http://localhost:8081/monitoring/network-probes
    âœ“ http://localhost:8081/monitoring/web-probes
    âœ“ http://localhost:8081/monitoring/system-exporters
    âœ“ http://localhost:8081/monitoring/database-exporters
    ```

27. âœ… **Validar integraÃ§Ã£o completa**
    - Dados carregam corretamente
    - Filtros funcionam
    - Colunas sÃ£o dinÃ¢micas
    - PaginaÃ§Ã£o funciona
    - Busca funciona

#### Dia 8: Polish e DocumentaÃ§Ã£o

**MANHÃƒ: Melhorias de UX**

28. âœ… **Adicionar indicadores visuais**
    - Badge com contador de online/offline
    - Indicador de Ãºltima atualizaÃ§Ã£o
    - Indicador de sincronizaÃ§Ã£o

29. âœ… **Adicionar tooltips informativos**
    - Explicar o que Ã© cada categoria
    - Explicar botÃ£o "Sincronizar Cache"
    - Explicar filtros avanÃ§ados

30. âœ… **Adicionar aÃ§Ãµes em lote** (opcional)
    - Selecionar mÃºltiplos itens
    - Exportar selecionados
    - AÃ§Ãµes bulk (se aplicÃ¡vel)

**TARDE: Commit do Frontend**

31. âœ… **Commit do frontend**
    ```bash
    git add frontend/
    git commit -m "feat(frontend): Implementar pÃ¡ginas de monitoramento dinÃ¢micas

    - Adicionar DynamicMonitoringPage (componente base Ãºnico)
    - Modificar useMetadataFields para aceitar contexto dinÃ¢mico
    - Adicionar 4 novas rotas: network-probes, web-probes, system-exporters, database-exporters
    - Atualizar menu de navegaÃ§Ã£o
    - Adicionar indicadores visuais e tooltips
    
    Features:
    - 100% dinÃ¢mico - funciona com qualquer categoria
    - Reutiliza componentes existentes (MetadataFilterBar, AdvancedSearchPanel)
    - ProTable com colunas configurÃ¡veis
    - Cache local de 5 minutos para metadata fields"
    ```

---

### FASE 4: Testes e ValidaÃ§Ã£o (Dias 9-10)

#### Dia 9: Testes Funcionais

**MANHÃƒ: Testes End-to-End**

32. âœ… **Teste 1: Network Probes**
    ```
    Passos:
    1. Acessar /monitoring/network-probes
    2. Validar que tabela carrega
    3. Validar que colunas sÃ£o: instance, job, status, company, site, etc
    4. Aplicar filtro de company
    5. Validar que dados filtram corretamente
    6. Clicar em "Sincronizar Cache"
    7. Validar que dados atualizam
    
    Resultado esperado: âœ“ Tudo funciona
    ```

33. âœ… **Teste 2: Web Probes**
    ```
    Passos:
    1. Acessar /monitoring/web-probes
    2. Validar que mostra apenas probes HTTP/HTTPS
    3. Validar que nÃ£o mostra probes ICMP/TCP
    4. Aplicar filtro avanÃ§ado (module = http_2xx)
    5. Validar que filtra corretamente
    
    Resultado esperado: âœ“ Tudo funciona
    ```

34. âœ… **Teste 3: System Exporters**
    ```
    Passos:
    1. Acessar /monitoring/system-exporters
    2. Validar que mostra node_exporter, windows_exporter
    3. NÃ£o deve mostrar blackbox targets
    4. Validar que colunas sÃ£o apropriadas (CPU, Memory, etc)
    
    Resultado esperado: âœ“ Tudo funciona
    ```

35. âœ… **Teste 4: Database Exporters**
    ```
    Passos:
    1. Acessar /monitoring/database-exporters
    2. Validar que mostra mysql, postgres, redis, mongodb
    3. Validar que colunas sÃ£o apropriadas
    
    Resultado esperado: âœ“ Tudo funciona
    ```

**TARDE: Testes de Performance**

36. âœ… **Teste de cache**
    ```bash
    # Limpar cache
    curl -X DELETE "http://172.16.1.26:8500/v1/kv/skills/eye/monitoring-types/cache?recurse"
    
    # Primeira carga (cold start)
    time curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes"
    # Esperado: 2-3 segundos
    
    # Segunda carga (cache hit)
    time curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes"
    # Esperado: <100ms
    
    # Resultado: âœ“ Cache funciona
    ```

37. âœ… **Teste de carga**
    ```bash
    # Instalar apache bench
    sudo apt install apache2-utils
    
    # Teste de carga
    ab -n 100 -c 10 "http://localhost:5000/api/v1/monitoring/data?category=network-probes"
    
    # Validar:
    # - Requests per second: >50
    # - Failed requests: 0
    # - Time per request: <200ms (mÃ©dia)
    ```

#### Dia 9.5: â­ Testes de PersistÃªncia (NOVO)

**OBJETIVO:** Validar que dados persistem apÃ³s reinÃ­cio do backend

**CENÃRIO 1: Verificar cache no Consul KV**
```bash
# 1. Verificar que dados estÃ£o no Consul KV
curl "http://172.16.1.26:8500/v1/kv/skills/eye/monitoring-types/cache?recurse&pretty"

# 2. Validar estrutura:
# - skills/eye/monitoring-types/cache/network-probes
# - skills/eye/monitoring-types/cache/web-probes
# - skills/eye/monitoring-types/cache/system-exporters
# - skills/eye/monitoring-types/cache/database-exporters

# 3. Validar que cada chave contÃ©m:
# - timestamp (CreatedIndex, ModifiedIndex)
# - data JSON completa
```

**CENÃRIO 2: Reiniciar backend e validar cache**
```bash
# 1. Carregar dados normalmente
curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes"

# 2. Reiniciar backend
cd /home/adrianofante/projetos/Skills-Eye
./restart-backend.sh

# 3. Aguardar 5 segundos

# 4. Requisitar novamente
time curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes"

# Resultado esperado: 
# - Resposta em <100ms (leu do cache)
# - Dados idÃªnticos ao passo 1
```

**CENÃRIO 3: Validar TTL de 5 minutos**
```bash
# 1. Carregar dados
curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes" > /tmp/data1.json

# 2. Aguardar 6 minutos

# 3. Carregar novamente
curl "http://localhost:5000/api/v1/monitoring/data?category=network-probes" > /tmp/data2.json

# 4. Comparar
diff /tmp/data1.json /tmp/data2.json

# Resultado esperado:
# - Dados podem ter mudado (cache foi invalidado)
# - Tempo de resposta no passo 3 > 2 segundos (cache miss)
```

**CRITÃ‰RIO DE SUCESSO:**
- âœ… Cache persiste no Consul KV
- âœ… Backend lÃª cache apÃ³s reinÃ­cio
- âœ… TTL de 5 minutos funciona corretamente

#### Dia 10: ValidaÃ§Ã£o Final e DocumentaÃ§Ã£o

**MANHÃƒ: Testes de Compatibilidade**

38. âœ… **Teste de compatibilidade com pÃ¡ginas antigas**
    ```
    1. Acessar /services (pÃ¡gina antiga)
    2. Validar que ainda funciona normalmente
    3. Acessar /blackbox-targets (pÃ¡gina antiga)
    4. Validar que ainda funciona normalmente
    
    Resultado esperado: âœ“ PÃ¡ginas antigas nÃ£o foram afetadas
    ```

39. âœ… **Teste de adiÃ§Ã£o de novo exporter**
    ```
    CenÃ¡rio: Adicionar novo exporter "kafka-exporter" no Prometheus
    
    Passos:
    1. Adicionar job no prometheus.yml:
       ```yaml
       - job_name: 'kafka-exporter'
         consul_sd_configs:
           - server: 'localhost:8500'
             services: ['kafka-exporter']
         relabel_configs:
           - source_labels: [__meta_consul_service_metadata_company]
             target_label: company
       ```
    
    2. Clicar em "Sincronizar Cache" na interface
    
    3. Validar que:
       - Kafka exporter aparece automaticamente
       - Ã‰ categorizado em "infrastructure-exporters"
       - Campos metadata sÃ£o detectados
    
    Resultado esperado: âœ“ Sistema detecta automaticamente
    ```

**TARDE: DocumentaÃ§Ã£o Final**

40. âœ… **Criar documentaÃ§Ã£o de uso**
    ```bash
    cat > docs/DYNAMIC_MONITORING_PAGES.md << 'EOF'
    # PÃ¡ginas de Monitoramento DinÃ¢micas
    
    ## VisÃ£o Geral
    
    O Skills Eye possui 4 pÃ¡ginas de monitoramento que funcionam 100% dinamicamente:
    
    1. **Network Probes** - Monitoramento de conectividade (ICMP, TCP, DNS)
    2. **Web Probes** - Monitoramento de aplicaÃ§Ãµes web (HTTP, HTTPS)
    3. **System Exporters** - Monitoramento de sistemas (Node, Windows)
    4. **Database Exporters** - Monitoramento de bancos de dados (MySQL, PostgreSQL)
    
    ## Como Funciona
    
    ### DetecÃ§Ã£o AutomÃ¡tica
    
    O sistema detecta automaticamente novos exporters adicionados no Prometheus:
    
    1. Jobs sÃ£o extraÃ­dos do `prometheus.yml` via SSH
    2. Cada job Ã© categorizado usando regras JSON do Consul KV
    3. Campos metadata sÃ£o extraÃ­dos dos `relabel_configs`
    4. Tudo Ã© armazenado em cache no Consul KV (5 minutos)
    
    ### Adicionar Novo Exporter
    
    Para adicionar um novo exporter:
    
    1. Configure no Prometheus:
       ```yaml
       - job_name: 'meu-novo-exporter'
         consul_sd_configs:
           - server: 'localhost:8500'
             services: ['meu-exporter']
         relabel_configs:
           - source_labels: [__meta_consul_service_metadata_company]
             target_label: company
       ```
    
    2. Recarregue o Prometheus:
       ```bash
       curl -X POST http://prometheus:9090/-/reload
       ```
    
    3. Sincronize o cache no Skills Eye:
       - Acesse qualquer pÃ¡gina de monitoramento
       - Clique no botÃ£o "Sincronizar Cache"
       - Aguarde 2-3 segundos
    
    4. Pronto! O novo exporter aparecerÃ¡ automaticamente na categoria apropriada.
    
    ### Adicionar Nova Categoria
    
    Se o sistema nÃ£o categorizar corretamente, adicione uma regra no Consul KV:
    
    ```bash
    # Editar regras
    consul kv get skills/eye/monitoring-types/categorization/rules > rules.json
    
    # Adicionar nova regra
    vim rules.json
    # {
    #   "id": "meu_novo_tipo",
    #   "priority": 85,
    #   "category": "infrastructure-exporters",
    #   "conditions": {
    #     "job_name_pattern": "^meu.*"
    #   }
    # }
    
    # Salvar de volta
    consul kv put skills/eye/monitoring-types/categorization/rules @rules.json
    ```
    
    ## Troubleshooting
    
    ### PÃ¡gina nÃ£o carrega dados
    
    1. Verificar que backend estÃ¡ rodando:
       ```bash
       curl http://localhost:5000/health
       ```
    
    2. Verificar cache KV:
       ```bash
       consul kv get skills/eye/monitoring-types/cache
       ```
    
    3. ForÃ§ar sincronizaÃ§Ã£o:
       - Clicar em "Sincronizar Cache"
       - Ou via API: `POST /api/v1/monitoring/sync-cache`
    
    ### Exporter nÃ£o aparece
    
    1. Verificar que job estÃ¡ no Prometheus:
       ```bash
       curl http://prometheus:9090/api/v1/targets | jq
       ```
    
    2. Verificar categorizaÃ§Ã£o:
       ```bash
       curl "http://localhost:5000/api/v1/monitoring-types-dynamic/from-prometheus?server=ALL" | jq '.all_types[] | select(.job_name=="meu-job")'
       ```
    
    3. Se categorizado errado, adicionar regra (ver acima)
    
    ### Campos nÃ£o aparecem
    
    1. Verificar metadata fields:
       ```bash
       curl http://localhost:5000/api/v1/metadata-fields/fields | jq
       ```
    
    2. Verificar relabel_configs no Prometheus:
       ```yaml
       # prometheus.yml deve ter:
       relabel_configs:
         - source_labels: [__meta_consul_service_metadata_MEU_CAMPO]
           target_label: meu_campo
       ```
    
    3. Sincronizar metadata fields:
       ```bash
       curl -X POST http://localhost:5000/api/v1/metadata-fields/sync
       ```
    EOF
    ```

41. âœ… **Atualizar README.md**
    ```bash
    # Adicionar seÃ§Ã£o no README.md do projeto
    cat >> README.md << 'EOF'
    
    ## PÃ¡ginas de Monitoramento DinÃ¢micas
    
    O Skills Eye possui 4 pÃ¡ginas de monitoramento que funcionam 100% dinamicamente:
    
    - **Network Probes** (`/monitoring/network-probes`) - ICMP, TCP, DNS, SSH
    - **Web Probes** (`/monitoring/web-probes`) - HTTP, HTTPS, POST
    - **System Exporters** (`/monitoring/system-exporters`) - Node, Windows, SNMP
    - **Database Exporters** (`/monitoring/database-exporters`) - MySQL, PostgreSQL, Redis, MongoDB
    
    ### CaracterÃ­sticas
    
    - âœ… **100% DinÃ¢mico** - Detecta automaticamente novos exporters
    - âœ… **Zero Hardcode** - Tudo vem do Prometheus e Consul KV
    - âœ… **Cache Inteligente** - 5 minutos de TTL, sincronizaÃ§Ã£o sob demanda
    - âœ… **Regras JSON** - CategorizaÃ§Ã£o configurÃ¡vel via KV
    
    Veja [documentaÃ§Ã£o completa](docs/DYNAMIC_MONITORING_PAGES.md) para mais detalhes.
    EOF
    ```

42. âœ… **Commit final**
    ```bash
    git add .
    git commit -m "docs: Adicionar documentaÃ§Ã£o completa das pÃ¡ginas dinÃ¢micas

    - Guia de uso detalhado
    - Troubleshooting
    - Exemplos de adiÃ§Ã£o de novos exporters
    - Atualizar README.md"
    
    git push origin feature/dynamic-monitoring-pages
    ```

---

### FASE 5: Deploy e ProduÃ§Ã£o (Dias 11-12)

#### Dia 11: â­ MigraÃ§Ã£o de CategorizaÃ§Ã£o (NOVO)

**OBJETIVO:** Migrar sistema de categorizaÃ§Ã£o existente para usar regras JSON no Consul KV

**MANHÃƒ: AnÃ¡lise do Sistema Atual**

43. âœ… **Identificar lÃ³gica de categorizaÃ§Ã£o atual**
    ```bash
    # Procurar por lÃ³gica hardcoded de categorizaÃ§Ã£o
    cd /home/adrianofante/projetos/Skills-Eye/backend
    grep -r "categoria" --include="*.py" .
    grep -r "category" --include="*.py" .
    
    # Identificar onde Services e BlackboxTargets categorizam
    # Objetivo: Migrar essa lÃ³gica para JSON no KV
    ```

44. âœ… **Mapear categorias existentes**
    ```python
    # Criar mapeamento das categorias atuais:
    categorias_atuais = {
        "services": [
            {"pattern": "node-exporter", "categoria": "system"},
            {"pattern": "mysql-exporter", "categoria": "database"},
            {"pattern": "blackbox", "categoria": "network"},
            # ... etc
        ]
    }
    
    # Salvar em: /tmp/categorias_mapeadas.json
    ```

**TARDE: ImplementaÃ§Ã£o da MigraÃ§Ã£o**

45. âœ… **Criar regras JSON no Consul KV**
    ```python
    # Script: migrate_categorization_to_kv.py
    import json
    import httpx
    
    # Ler categorizaÃ§Ã£o mapeada
    with open('/tmp/categorias_mapeadas.json') as f:
        categorias = json.load(f)
    
    # Popular no Consul KV
    CONSUL_URL = "http://172.16.1.26:8500"
    for service_type, rules in categorias.items():
        key = f"skills/eye/monitoring-types/rules/{service_type}"
        data = {
            "rules": rules,
            "version": "1.0",
            "migrated_from": "hardcoded_logic",
            "created_at": "2025-01-11"
        }
        
        response = httpx.put(
            f"{CONSUL_URL}/v1/kv/{key}",
            json=data
        )
        print(f"âœ“ Migrado: {service_type}")
    ```

46. âœ… **Atualizar Services.tsx e BlackboxTargets.tsx**
    ```typescript
    // ANTES (hardcoded):
    const categoria = getCategoriaPorNome(service.name);
    
    // DEPOIS (dinÃ¢mico):
    const categoria = await consulAPI.getCategoria(service.name);
    ```

47. âœ… **Testes de regressÃ£o**
    ```bash
    # Validar que categorizaÃ§Ã£o funciona igual:
    # 1. Abrir /services
    # 2. Validar que todas as categorias aparecem corretamente
    # 3. Comparar com versÃ£o anterior (screenshot)
    
    # CritÃ©rio de sucesso: Zero diferenÃ§as visuais
    ```

#### Dia 12: Deploy

**MANHÃƒ: PreparaÃ§Ã£o para Deploy**

48. âœ… **Criar Pull Request**
    ```
    TÃ­tulo: feat: Implementar pÃ¡ginas de monitoramento 100% dinÃ¢micas
    
    DescriÃ§Ã£o:
    Este PR adiciona 4 novas pÃ¡ginas de monitoramento que funcionam de forma 100% dinÃ¢mica, 
    detectando automaticamente novos exporters do Prometheus.
    
    ## MudanÃ§as
    
    ### Backend
    - Adicionar ConsulKVConfigManager com cache TTL
    - Adicionar CategorizationRuleEngine baseado em JSON
    - Adicionar DynamicQueryBuilder com Jinja2
    - Modificar monitoring_types_dynamic para usar cache KV
    - Adicionar endpoint unificado /monitoring/data
    
    ### Frontend
    - Adicionar DynamicMonitoringPage (componente base Ãºnico)
    - Modificar useMetadataFields para aceitar contexto dinÃ¢mico
    - Adicionar 4 novas rotas
    - Atualizar menu de navegaÃ§Ã£o
    
    ## Testes
    
    - âœ… Testes unitÃ¡rios backend (100% cobertura nos novos mÃ³dulos)
    - âœ… Testes E2E frontend (todas as 4 pÃ¡ginas)
    - âœ… Teste de performance (cache <100ms, extraÃ§Ã£o ~2s)
    - âœ… Teste de compatibilidade (pÃ¡ginas antigas funcionam)
    
    ## DocumentaÃ§Ã£o
    
    - âœ… DYNAMIC_MONITORING_PAGES.md
    - âœ… README.md atualizado
    - âœ… CÃ³digo comentado em portuguÃªs
    
    ## Breaking Changes
    
    Nenhum. PÃ¡ginas antigas (Services, BlackboxTargets) continuam funcionando.
    
    ## Closes
    
    Closes #123 (se houver issue)
    ```

44. âœ… **Code review**
    - Solicitar review de pelo menos 2 pessoas
    - Aguardar aprovaÃ§Ã£o
    - Corrigir issues apontados

**TARDE: Deploy em ProduÃ§Ã£o**

45. âœ… **Merge para main**
    ```bash
    # ApÃ³s aprovaÃ§Ã£o do PR
    git checkout main
    git pull origin main
    git merge feature/dynamic-monitoring-pages
    git push origin main
    ```

46. âœ… **Deploy backend**
    ```bash
    # SSH no servidor
    ssh user@172.16.1.26
    
    # Ir para pasta do projeto
    cd /opt/skills-eye
    
    # Pull da main
    git pull origin main
    
    # Ativar venv e instalar dependÃªncias
    source venv/bin/activate
    pip install -r requirements.txt
    
    # Reiniciar backend
    sudo systemctl restart skills-eye-backend
    
    # Verificar logs
    sudo journalctl -u skills-eye-backend -f
    ```

47. âœ… **Deploy frontend**
    ```bash
    # Ainda no servidor
    cd /opt/skills-eye/frontend
    
    # Instalar dependÃªncias
    npm install
    
    # Build de produÃ§Ã£o
    npm run build
    
    # Copiar para nginx (se aplicÃ¡vel)
    sudo cp -r dist/* /var/www/skills-eye/
    
    # Reiniciar nginx
    sudo systemctl restart nginx
    ```

48. âœ… **ValidaÃ§Ã£o pÃ³s-deploy**
    ```
    âœ“ Acessar https://skills-eye.skillsit.com.br
    âœ“ Validar que 4 novas pÃ¡ginas carregam
    âœ“ Validar que dados sÃ£o corretos
    âœ“ Validar que cache funciona
    âœ“ Validar que nÃ£o hÃ¡ erros no console
    ```

49. âœ… **Monitoramento**
    ```bash
    # Configurar alertas (se aplicÃ¡vel)
    # - Alert se endpoint /monitoring/data > 2s
    # - Alert se cache hit rate < 80%
    # - Alert se extraÃ§Ã£o SSH > 5s
    ```

50. âœ… **Comunicar usuÃ¡rios**
    ```
    Assunto: [Skills Eye] Novas pÃ¡ginas de monitoramento disponÃ­veis!
    
    OlÃ¡ equipe,
    
    Temos o prazer de anunciar 4 novas pÃ¡ginas de monitoramento no Skills Eye:
    
    1. Network Probes - Monitoramento de conectividade
    2. Web Probes - Monitoramento de aplicaÃ§Ãµes web
    3. System Exporters - Monitoramento de sistemas
    4. Database Exporters - Monitoramento de bancos de dados
    
    Principais features:
    - âœ… 100% dinÃ¢mico - detecta automaticamente novos exporters
    - âœ… Filtros avanÃ§ados
    - âœ… Colunas configurÃ¡veis
    - âœ… Cache inteligente
    
    As pÃ¡ginas antigas (Services, Blackbox Targets) continuam disponÃ­veis como backup.
    
    Acesse: https://skills-eye.skillsit.com.br
    
    DÃºvidas? Veja a documentaÃ§Ã£o: https://...
    
    Att,
    Equipe Skills Eye
    ```

---

## âœ… VALIDAÃ‡ÃƒO E TESTES

### 7.1 Checklist de ValidaÃ§Ã£o Completo

#### Backend

```markdown
- [ ] ConsulKVConfigManager
  - [ ] Salva e recupera dados do KV
  - [ ] Cache funciona (TTL 5min)
  - [ ] InvalidaÃ§Ã£o de cache funciona
  - [ ] Testes unitÃ¡rios passam
  
- [ ] CategorizationRuleEngine
  - [ ] Carrega regras do KV
  - [ ] Categoriza jobs corretamente
  - [ ] Fallback para custom-exporters
  - [ ] Testes unitÃ¡rios passam
  
- [ ] DynamicQueryBuilder
  - [ ] Renderiza templates Jinja2
  - [ ] Substitui variÃ¡veis corretamente
  - [ ] ParÃ¢metros opcionais funcionam
  - [ ] Testes unitÃ¡rios passam
  
- [ ] monitoring_types_dynamic.py
  - [ ] Cache KV funciona
  - [ ] ExtraÃ§Ã£o SSH funciona
  - [ ] Usa CategorizationRuleEngine
  - [ ] Endpoint /from-prometheus retorna dados corretos
  
- [ ] monitoring_unified.py
  - [ ] Endpoint /data funciona para todas categorias
  - [ ] Filtra por servidor
  - [ ] Executa queries PromQL
  - [ ] Retorna dados formatados
  - [ ] Endpoint /sync-cache funciona
```

#### Frontend

```markdown
- [ ] DynamicMonitoringPage
  - [ ] Renderiza para todas as 4 categorias
  - [ ] Colunas sÃ£o dinÃ¢micas
  - [ ] Filtros funcionam
  - [ ] Busca avanÃ§ada funciona
  - [ ] Sincronizar cache funciona
  
- [ ] useMetadataFields
  - [ ] Aceita contexto dinÃ¢mico
  - [ ] Cache funciona (5min)
  - [ ] Filtra campos corretamente
  
- [ ] Rotas
  - [ ] /monitoring/network-probes carrega
  - [ ] /monitoring/web-probes carrega
  - [ ] /monitoring/system-exporters carrega
  - [ ] /monitoring/database-exporters carrega
  
- [ ] Menu
  - [ ] Novo grupo "Monitoramento por Tipo" aparece
  - [ ] 4 itens dentro do grupo
  - [ ] NavegaÃ§Ã£o funciona
```

#### IntegraÃ§Ã£o

```markdown
- [ ] End-to-End
  - [ ] UsuÃ¡rio acessa /monitoring/network-probes
  - [ ] Dados carregam do backend
  - [ ] Filtro de company funciona
  - [ ] Sincronizar cache atualiza dados
  - [ ] PÃ¡ginas antigas ainda funcionam
  
- [ ] Performance
  - [ ] Cache hit < 100ms
  - [ ] Cache miss ~ 2-3s
  - [ ] Carga de 100 requests funciona
  
- [ ] Compatibilidade
  - [ ] Firefox
  - [ ] Chrome
  - [ ] Edge
  - [ ] Mobile (responsivo)
```

---

## ğŸ“š DOCUMENTAÃ‡ÃƒO NECESSÃRIA

### 8.1 Documentos a Criar

1. **DYNAMIC_MONITORING_PAGES.md** - Guia completo de uso
2. **API_UNIFIED_ENDPOINT.md** - DocumentaÃ§Ã£o da API unificada
3. **CATEGORIZATION_RULES.md** - Como funcionam as regras
4. **TROUBLESHOOTING.md** - SoluÃ§Ã£o de problemas comuns
5. **CHANGELOG.md** - Atualizar com novas features

### 8.2 DocumentaÃ§Ã£o em CÃ³digo

**TODOS os arquivos novos devem ter:**

```python
"""
Nome do MÃ³dulo - DescriÃ§Ã£o Breve

RESPONSABILIDADES:
- Responsabilidade 1
- Responsabilidade 2

DEPENDÃŠNCIAS:
- MÃ³dulo X
- Biblioteca Y

EXEMPLO DE USO:
```python
# CÃ³digo de exemplo
```

TESTES:
- backend/tests/test_nome_modulo.py
"""
```

---

## ğŸ‰ CONCLUSÃƒO

Este plano fornece **TODAS as informaÃ§Ãµes necessÃ¡rias** para implementar o sistema de monitoramento 100% dinÃ¢mico do Skills Eye.

### âœ… Checklist Final

- âœ… **AnÃ¡lise do projeto real** - baseado em cÃ³digo existente
- âœ… **RecomendaÃ§Ãµes tÃ©cnicas** - embasadas em pesquisa web
- âœ… **Componentes detalhados** - cÃ³digo completo fornecido
- âœ… **Plano de implementaÃ§Ã£o** - passo a passo de 11 dias
- âœ… **Testes e validaÃ§Ã£o** - checklists completos
- âœ… **DocumentaÃ§Ã£o** - guias e exemplos

### ğŸ“Š Estimativas

- **Tempo total:** 11 dias Ãºteis (2,2 semanas)
- **Linhas de cÃ³digo:** ~2000 (backend + frontend)
- **Arquivos novos:** 8 (4 backend + 4 frontend/modificados)
- **Testes unitÃ¡rios:** 15+ cenÃ¡rios
- **Performance esperada:** <100ms (cache hit), ~2s (cache miss)

### ğŸš€ PrÃ³ximos Passos

1. **Revisar documento completo** - garantir entendimento
2. **Preparar ambiente** - Fase 1, Dia 1
3. **ComeÃ§ar implementaÃ§Ã£o** - seguir plano passo a passo
4. **Validar constantemente** - apÃ³s cada fase
5. **Deploy com confianÃ§a** - apÃ³s todos os testes passarem

---

**Este documento Ã© definitivo e estÃ¡ pronto para ser usado por outra IA ou desenvolvedor para implementar o sistema completo.**

**DÃºvidas?** Consulte as seÃ§Ãµes especÃ­ficas ou entre em contato.

**Boa implementaÃ§Ã£o! ğŸš€**