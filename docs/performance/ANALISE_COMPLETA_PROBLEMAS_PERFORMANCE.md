# ANÁLISE COMPLETA - PROBLEMAS DE PERFORMANCE E ARQUITETURA
## Consul Manager Web - Documentação Técnica Detalhada

**Data**: 2025-11-06 (Atualizado)
**Sessão**: Análise de problemas de timeout e performance
**Status**: CONTEXT API IMPLEMENTADO - Aguardando Teste de Validação

---

## ÍNDICE

1. [Resumo Executivo](#resumo-executivo)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Fluxo de Dados Completo](#fluxo-de-dados-completo)
4. [Problemas Identificados](#problemas-identificados)
5. [Tentativas de Solução](#tentativas-de-solução)
6. [Estado Atual](#estado-atual)
7. [Análise de Root Cause](#análise-de-root-cause)
8. [Próximos Passos Recomendados](#próximos-passos-recomendados)

---

## RESUMO EXECUTIVO

### Problema Principal
Sistema apresenta timeouts de 15-60 segundos ao carregar páginas (Exporters, Services, Blackbox) após reiniciar a aplicação ou limpar cache do navegador.

### Sintomas
- **Cold Start**: Primeira carga após restart demora 30-60+ segundos
- **Múltiplos Timeouts**: Erros ECONNABORTED com timeout exceeded
- **Requisições Duplicadas**: Mesmo endpoint chamado 3+ vezes simultaneamente
- **SSH Overhead**: Backend faz conexões SSH em tempo real durante requisições

### Causa Raiz (Hipótese Atual)
1. **Requisições Síncronas Bloqueantes**: Frontend faz múltiplas chamadas ao mesmo endpoint
2. **SSH em Request Path**: Backend conecta via SSH aos servidores Prometheus durante requisições HTTP
3. **Cache Inconsistente**: KV do Consul nem sempre está populado com dados recentes
4. **Falta de Loading States**: Usuário não sabe que sistema está processando

---

## ARQUITETURA DO SISTEMA

### Visão Geral

```
┌─────────────────────────────────────────────────────────────────┐
│                         USUÁRIO                                  │
└───────────────────────────┬─────────────────────────────────────┘
                            │
                            │ HTTP (localhost:8081)
                            ▼
┌─────────────────────────────────────────────────────────────────┐
│                    FRONTEND (React + Vite)                       │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │
│  │   Services   │  │   Exporters  │  │   Blackbox   │          │
│  │   (página)   │  │   (página)   │  │   (página)   │          │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘          │
│         │                  │                  │                  │
│         └──────────────────┴──────────────────┘                 │
│                            │                                     │
│                            │ usa hooks                          │
│                            ▼                                     │
│         ┌──────────────────────────────────────┐                │
│         │  useTableFields('exporters')         │ ◄─┐            │
│         │  useFormFields('exporters')          │   │ 3 chamadas │
│         │  useFilterFields('exporters')        │ ──┘ simultâneas│
│         └──────────────────┬───────────────────┘                │
│                            │                                     │
│                            │ axios.get()                        │
└────────────────────────────┼─────────────────────────────────────┘
                             │
                             │ HTTP (localhost:5000/api/v1)
                             ▼
┌─────────────────────────────────────────────────────────────────┐
│                    BACKEND (FastAPI + Python)                    │
│                                                                  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │  /api/v1/prometheus-config/fields                         │  │
│  │  └─► Endpoint CRÍTICO - chamado 3x simultaneamente       │  │
│  └──────────────────────┬───────────────────────────────────┘  │
│                         │                                       │
│                         │ TENTA ler do KV primeiro             │
│                         ▼                                       │
│         ┌───────────────────────────────┐                      │
│         │  Consul KV                    │                      │
│         │  skills/cm/metadata/fields    │                      │
│         │  (cache dos campos)           │                      │
│         └───────────┬───────────────────┘                      │
│                     │                                           │
│                     │ Se KV vazio ou force_refresh             │
│                     ▼                                           │
│         ┌───────────────────────────────┐                      │
│         │  multi_config_manager.py      │                      │
│         │  extract_all_fields_with_status() │                 │
│         └───────────┬───────────────────┘                      │
│                     │                                           │
│                     │ Conecta via SSH (LENTO!)                │
│                     ▼                                           │
│         ┌───────────────────────────────┐                      │
│         │  SSH para 3 servidores        │                      │
│         │  em PARALELO:                 │                      │
│         │  • 172.16.1.26 (palmas)       │                      │
│         │  • 172.16.200.14 (rio)        │                      │
│         │  • 11.144.0.21 (dtc)          │                      │
│         └───────────┬───────────────────┘                      │
│                     │                                           │
│                     │ Lê prometheus.yml de cada servidor       │
│                     │ (20-30 segundos TOTAL)                   │
│                     ▼                                           │
│         ┌───────────────────────────────┐                      │
│         │  Extrai relabel_configs       │                      │
│         │  Gera MetadataField[]         │                      │
│         │  Salva no KV                  │                      │
│         └───────────────────────────────┘                      │
└─────────────────────────────────────────────────────────────────┘
                             │
                             │ SSH (porta 22/5522)
                             ▼
┌─────────────────────────────────────────────────────────────────┐
│              SERVIDORES PROMETHEUS (Remoto)                      │
│                                                                  │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐│
│  │ 172.16.1.26     │  │ 172.16.200.14   │  │ 11.144.0.21     ││
│  │ (palmas-master) │  │ (rio)           │  │ (dtc)           ││
│  │                 │  │                 │  │                 ││
│  │ /etc/prometheus/│  │ /etc/prometheus/│  │ /etc/prometheus/││
│  │  prometheus.yml │  │  prometheus.yml │  │  prometheus.yml ││
│  │  blackbox.yml   │  │  blackbox.yml   │  │  blackbox.yml   ││
│  └─────────────────┘  └─────────────────┘  └─────────────────┘│
└─────────────────────────────────────────────────────────────────┘
```

### Stack Tecnológica

#### Frontend
- **Framework**: React 19.1.1
- **Build Tool**: Vite 7.1.14 (rolldown-vite)
- **UI Library**: Ant Design 5.27.6
- **Pro Components**: @ant-design/pro-components 2.8.10
- **HTTP Client**: Axios
- **Routing**: React Router DOM 7.9.4
- **Dev Server**: localhost:8081

#### Backend
- **Framework**: FastAPI (Python 3.12)
- **Async Runtime**: asyncio + httpx
- **SSH Client**: paramiko
- **YAML Parser**: ruamel.yaml (preserva comentários)
- **Service Discovery**: HashiCorp Consul
- **Dev Server**: localhost:5000

#### Infraestrutura
- **Service Registry**: Consul (172.16.1.26:8500)
- **Monitoring**: Prometheus (3 instâncias)
- **KV Store**: Consul KV (namespace: skills/cm/)
- **SSH Ports**: 22 (padrão), 5522 (alternativo)

---

## FLUXO DE DADOS COMPLETO

### 1. Inicialização da Aplicação

```
PASSO 1: Usuário acessa http://localhost:8081
├─► Vite dev server serve index.html
├─► React carrega App.tsx
└─► Componentes montam na ordem:
    ├─► BrowserRouter
    ├─► ConfigProvider (Ant Design)
    ├─► MetadataFieldsProvider (NOVO - Context API)
    │   └─► useEffect(() => loadFields(), [])
    │       └─► GET /api/v1/prometheus-config/fields (60s timeout)
    ├─► ProLayout (Menu lateral)
    └─► Routes (Renderiza página atual)

PASSO 2: MetadataFieldsProvider carrega campos
├─► Faz UMA requisição ao montar
├─► Armazena resultado no Context
└─► Todos os componentes filhos compartilham esse estado

PASSO 3: Página específica carrega (ex: Exporters)
├─► Monta componente Exporters
├─► useTableFields('exporters')  ◄─┐
├─► useFormFields('exporters')     ├─ Leem do Context (NÃO fazem requisição)
└─► useFilterFields('exporters')  ◄─┘
```

### 2. Endpoint `/api/v1/prometheus-config/fields`

**Propósito**: Retornar TODOS os campos metadata extraídos dos arquivos prometheus.yml de TODOS os servidores

**Fluxo de Execução**:

```python
# backend/api/prometheus_config.py linha 219-300

@router.get("/fields", response_model=FieldsResponse)
async def get_available_fields(
    enrich_with_values: bool = Query(True),
    force_refresh: bool = Query(False)
):
    """
    Retorna campos metadata extraídos do prometheus.yml

    OTIMIZAÇÃO: Lê do KV primeiro (INSTANTÂNEO)
    Só faz SSH se KV vazio ou force_refresh=true
    """

    # PASSO 1: Tentar ler do Consul KV (RÁPIDO - 50-200ms)
    if not force_refresh:
        try:
            kv_manager = KVManager()
            kv_data = await kv_manager.get_json('skills/cm/metadata/fields')

            if kv_data and kv_data.get('fields'):
                # SUCESSO: Retorna do cache
                return FieldsResponse(
                    success=True,
                    fields=kv_data['fields'],
                    total=len(kv_data['fields']),
                    from_cache=True  # ← Indica que veio do cache
                )
        except Exception as e:
            # KV não disponível, cai no fluxo SSH
            logger.warning(f"KV não disponível: {e}")

    # PASSO 2: KV vazio ou force_refresh - Extrair via SSH (LENTO - 20-30s)
    logger.info("[FIELDS] Extração via SSH - 3 servidores em PARALELO")
    extraction_result = multi_config.extract_all_fields_with_status()

    fields = extraction_result['fields']

    # PASSO 3: Salvar no KV para próximas requisições
    await kv_manager.put_json(
        key='skills/cm/metadata/fields',
        value={
            'fields': [f.to_dict() for f in fields],
            'extraction_status': {...},
            'last_updated': datetime.now().isoformat()
        }
    )

    return FieldsResponse(
        success=True,
        fields=fields,
        from_cache=False  # ← Indica que veio do SSH
    )
```

**Dependências**:

```
/api/v1/prometheus-config/fields
│
├─► KVManager (core/kv_manager.py)
│   └─► Consul HTTP API
│       └─► GET /v1/kv/skills/cm/metadata/fields
│
└─► MultiConfigManager (core/multi_config_manager.py)
    └─► extract_all_fields_with_status()
        │
        ├─► Para cada servidor (3 servidores):
        │   ├─► SSH via paramiko
        │   ├─► Lê /etc/prometheus/prometheus.yml
        │   ├─► Lê /etc/prometheus/blackbox.yml
        │   ├─► Parse com ruamel.yaml
        │   └─► Extrai relabel_configs
        │
        └─► Consolida campos de todos os servidores
            └─► Retorna MetadataField[]
```

### 3. Extração de Campos via SSH (CRÍTICO - GARGALO)

**Arquivo**: `backend/core/multi_config_manager.py`
**Função**: `extract_all_fields_with_status()`
**Linha**: 506-610

```python
def extract_all_fields_with_status(self) -> Dict[str, Any]:
    """
    PROBLEMA: Este método é o GARGALO principal

    Extrai campos de 3 servidores em PARALELO usando ThreadPoolExecutor
    Cada servidor leva ~20-30s individualmente
    Em paralelo, total = tempo do servidor mais lento (~21-30s)
    """

    # PASSO 1: Verificar cache em memória
    if self._fields_cache:
        # Cache HIT: Retorna imediatamente
        return {
            'fields': self._fields_cache,
            'server_status': [...],
            'from_cache': True
        }

    # PASSO 2: Cache MISS - Processar 3 servidores em paralelo
    server_results = []
    with ThreadPoolExecutor(max_workers=3) as executor:
        # Submete 3 tasks simultaneamente
        future_to_host = {
            executor.submit(self._process_single_server, host): host
            for host in self.hosts  # 3 hosts
        }

        # Aguarda resultados (BLOQUEANTE - 20-30s)
        for future in as_completed(future_to_host):
            result = future.result()
            server_results.append(result)

    # PASSO 3: Consolidar resultados
    all_fields_map = {}
    for result in server_results:
        # Merge campos de todos os servidores
        local_fields = result.get('fields_map', {})
        for field_name, field in local_fields.items():
            if field_name not in all_fields_map:
                all_fields_map[field_name] = field

    # PASSO 4: Salvar em cache
    self._fields_cache = list(all_fields_map.values())

    return {
        'fields': self._fields_cache,
        'server_status': server_results,
        'from_cache': False
    }
```

**Processamento de Servidor Individual**:

```python
def _process_single_server(self, host: ConfigHost) -> Dict[str, Any]:
    """
    Processa UM servidor via SSH

    Tempo médio: 20-30 segundos por servidor
    """
    start_time = time.time()

    # PASSO 1: Conectar SSH (2-5s)
    ssh_client = self._get_ssh_client(host)

    # PASSO 2: Listar arquivos .yml (1-2s)
    config_files = self._list_config_files(ssh_client, host)
    # Retorna: [prometheus.yml, blackbox.yml, alertmanager.yml, ...]

    # PASSO 3: Para cada arquivo .yml (5-10s por arquivo)
    fields_map = {}
    for config_file in config_files:
        # Ler conteúdo via SSH
        yaml_content = self._read_remote_file(ssh_client, config_file.path)

        # Parse YAML
        config = yaml.safe_load(yaml_content)

        # Se prometheus.yml, extrair external_labels (IMPORTANTE!)
        if 'global' in config and 'prometheus' in config_file.filename:
            external_labels = config['global'].get('external_labels', {})
            # external_labels = {
            #     'site': 'palmas',
            #     'cluster': 'palmas-master',
            #     'datacenter': 'skillsit-palmas-to',
            #     'environment': 'production'
            # }

        # Extrair campos de relabel_configs
        if 'scrape_configs' in config:
            for job in config['scrape_configs']:
                for relabel in job.get('relabel_configs', []):
                    # Exemplo:
                    # source_labels: ["__meta_consul_service_metadata_company"]
                    # target_label: "company"

                    target = relabel.get('target_label')
                    if target:
                        fields_map[target] = MetadataField(
                            name=target,
                            source_label=relabel.get('source_labels', [])[0],
                            field_type='string',
                            # ... outros atributos
                        )

    duration_ms = int((time.time() - start_time) * 1000)

    return {
        'hostname': host.hostname,
        'success': True,
        'duration_ms': duration_ms,  # ~20000-30000ms
        'fields_map': fields_map,
        'external_labels': external_labels
    }
```

### 4. Endpoint `/api/v1/nodes`

**Propósito**: Retornar lista de nós do cluster Consul com contagem de serviços

**Arquivo**: `backend/api/nodes.py`

```python
# Cache global de 30 segundos
_nodes_cache: Optional[Dict] = None
_nodes_cache_time: float = 0
NODES_CACHE_TTL = 30

@router.get("/nodes")
async def get_nodes():
    """
    Retorna nós do cluster com cache de 30s

    PROBLEMA: Ainda lento no cold start (2-5s)
    """
    current_time = time.time()

    # Verificar cache
    if _nodes_cache and (current_time - _nodes_cache_time) < 30:
        return _nodes_cache  # RÁPIDO: <1ms

    # Cache expirado - Buscar dados
    consul = ConsulManager()
    members = await consul.get_members()  # ~500ms

    # Para cada nó, contar serviços (LENTO!)
    async def get_service_count(member):
        member["services_count"] = 0
        try:
            temp_consul = ConsulManager(host=member["addr"])
            services = await asyncio.wait_for(
                temp_consul.get_services(),
                timeout=5.0  # ← Pode dar timeout aqui
            )
            member["services_count"] = len(services)
        except:
            pass  # Silencioso
        return member

    # Processar todos em paralelo (2-5s total)
    enriched_members = await asyncio.gather(*[
        get_service_count(m) for m in members
    ])

    result = {
        "success": True,
        "data": enriched_members,
        "total": len(enriched_members)
    }

    # Atualizar cache
    _nodes_cache = result
    _nodes_cache_time = current_time

    return result
```

### 5. Campos Dinâmicos - Sistema de Metadata

**Conceito**: Campos são extraídos AUTOMATICAMENTE do prometheus.yml ao invés de serem hardcoded

**Origem dos Campos**:

```yaml
# /etc/prometheus/prometheus.yml (em cada servidor)

global:
  external_labels:
    cluster: 'palmas-master'
    datacenter: 'skillsit-palmas-to'
    environment: 'production'
    site: 'palmas'  # ← IMPORTANTE para multi-site

scrape_configs:
  - job_name: 'consul-services'
    consul_sd_configs:
      - server: '172.16.1.26:8500'

    relabel_configs:
      # Campo: company
      - source_labels: [__meta_consul_service_metadata_company]
        target_label: company  # ← VIRA CAMPO DINÂMICO

      # Campo: env
      - source_labels: [__meta_consul_service_metadata_env]
        target_label: env  # ← VIRA CAMPO DINÂMICO

      # Campo: region
      - source_labels: [__meta_consul_service_metadata_region]
        target_label: region  # ← VIRA CAMPO DINÂMICO
```

**Processamento**:

```
prometheus.yml (servidor remoto)
         │
         │ SSH + ruamel.yaml
         ▼
MetadataField {
    name: "company",
    display_name: "Empresa",
    source_label: "__meta_consul_service_metadata_company",
    field_type: "string",
    required: false,
    show_in_table: true,
    show_in_form: true,
    show_in_filter: true,
    order: 1
}
         │
         │ Salvo no Consul KV
         ▼
skills/cm/metadata/fields = {
    fields: [
        { name: "company", ... },
        { name: "env", ... },
        { name: "region", ... }
    ]
}
         │
         │ Frontend lê via Context
         ▼
useTableFields('exporters') = [
    { name: "company", ... },
    { name: "env", ... }
]
         │
         │ Gera colunas dinamicamente
         ▼
ProTable columns={[
    { title: "Empresa", dataIndex: ["Meta", "company"] },
    { title: "Ambiente", dataIndex: ["Meta", "env"] }
]}
```

**Vantagens**:
- ✅ Não precisa alterar código ao adicionar campo novo
- ✅ Frontend e Backend sincronizados automaticamente
- ✅ Múltiplos servidores Prometheus com campos diferentes

**Desvantagens** (PROBLEMAS ATUAIS):
- ❌ Extração via SSH é LENTA (20-30s)
- ❌ Cache inconsistente (às vezes KV vazio)
- ❌ Requisições duplicadas (3x o mesmo endpoint)

---

## PROBLEMAS IDENTIFICADOS

### Problema #1: Requisições Duplicadas

**Descrição**: Página faz 3 chamadas simultâneas ao mesmo endpoint

**Código Problemático**:

```typescript
// frontend/src/pages/Exporters.tsx linha 140-142

const { tableFields } = useTableFields('exporters');    // ← Requisição 1
const { formFields } = useFormFields('exporters');      // ← Requisição 2
const { filterFields } = useFilterFields('exporters');  // ← Requisição 3

// PROBLEMA: Cada hook fazia sua própria requisição
// ANTES da otimização via Context
```

**Evidência**:
```
Network Tab (Chrome DevTools):
┌────────────────────────────────────────────────────────┐
│ GET /api/v1/prometheus-config/fields?enrich=true       │ 30.2s
│ GET /api/v1/prometheus-config/fields?enrich=true       │ 30.1s
│ GET /api/v1/prometheus-config/fields?enrich=true       │ 30.3s
└────────────────────────────────────────────────────────┘
   ▲                 ▲                 ▲
   │                 │                 │
   tableFields   formFields      filterFields
```

**Impacto**:
- **Tempo Total**: 30s x 3 = 90s (sequencial) ou 30s (paralelo, mas sobrecarga no backend)
- **Carga no Backend**: 3x processamento SSH
- **Experiência do Usuário**: Timeout errors, tela branca

**Tentativa de Solução**:
```typescript
// IMPLEMENTADO: Context API para compartilhar estado

// App.tsx
<MetadataFieldsProvider>  {/* ← Faz UMA requisição ao montar */}
  <Routes>
    <Route path="/exporters" element={<Exporters />} />
  </Routes>
</MetadataFieldsProvider>

// useMetadataFields.ts
export function useTableFields(context?: string) {
  const { fields: allFields } = useMetadataFieldsContext(); // ← Lê do Context

  return allFields
    .filter(f => f.show_in_table)
    .filter(f => context ? f[`show_in_${context}`] : true);
}
```

**Status**: ✅ IMPLEMENTADO mas não testado completamente

### Problema #2: SSH em Request Path

**Descrição**: Backend faz conexões SSH durante requisições HTTP síncronas

**Fluxo Atual**:

```
Usuário clica em "Exporters"
         │
         │ HTTP GET
         ▼
Backend recebe /api/v1/prometheus-config/fields
         │
         │ Verifica KV
         ▼
KV vazio ou expirado
         │
         │ INICIA SSH (BLOQUEANTE!)
         ▼
Conecta em 172.16.1.26 via SSH  ◄─┐
Lê prometheus.yml (5-10s)         │ Em paralelo
Conecta em 172.16.200.14 via SSH  │ mas ainda
Lê prometheus.yml (5-10s)         │ BLOQUEANTE
Conecta em 11.144.0.21 via SSH    │ para a
Lê prometheus.yml (20-30s!) ◄─────┘ requisição HTTP
         │
         │ Parse + Consolidação (1-2s)
         ▼
Retorna resposta HTTP após 20-30s
```

**Problema**: Operações I/O lentas (SSH + leitura de arquivo) estão no caminho crítico da requisição HTTP

**Impacto**:
- **Timeout**: Frontend desiste após 60s
- **Escalabilidade**: Backend trava aguardando SSH
- **Experiência**: Usuário vê tela branca por 30+ segundos

**Solução Ideal** (NÃO IMPLEMENTADA):

```
Opção A: Job Assíncrono em Background
┌─────────────────────────────────────────────┐
│ Cronjob (a cada 5 minutos):                │
│   1. Conecta SSH nos 3 servidores           │
│   2. Extrai campos                          │
│   3. Salva no KV                            │
│                                             │
│ Requisição HTTP:                            │
│   1. Lê do KV (sempre populado)             │
│   2. Retorna imediatamente (<100ms)         │
└─────────────────────────────────────────────┘

Opção B: Cache Pre-Warming
┌─────────────────────────────────────────────┐
│ Backend startup:                            │
│   1. Inicializa servidor FastAPI            │
│   2. Em background thread:                  │
│      - Conecta SSH                          │
│      - Popula cache                         │
│   3. Marca "ready" quando cache populado    │
│                                             │
│ Requisição HTTP:                            │
│   1. Verifica se "ready"                    │
│   2. Lê do cache (sempre disponível)        │
│   3. Retorna imediatamente                  │
└─────────────────────────────────────────────┘
```

**Status**: ❌ NÃO IMPLEMENTADO - Apenas adicionada leitura do KV (paliativo)

### Problema #3: Cache Inconsistente

**Descrição**: KV do Consul nem sempre está populado com dados atualizados

**Cenários Problemáticos**:

1. **Backend reinicia**: Cache em memória (`_fields_cache`) perdido
2. **KV nunca foi populado**: Primeira instalação
3. **Dados antigos no KV**: Servidor Prometheus mudou mas KV não foi atualizado
4. **Múltiplas instâncias**: Se houver >1 backend, caches divergem

**Evidência**:

```bash
# Teste realizado durante sessão
$ curl http://localhost:5000/api/v1/kv/value?key=skills/cm/metadata/fields

# ANTES da re-extração:
{
  "external_labels": {}  # ← VAZIO!
}

# APÓS forçar extração:
{
  "external_labels": {
    "site": "palmas",
    "cluster": "palmas-master",
    ...
  }
}
```

**Root Cause**:
- Código salva no KV APENAS quando faz extração SSH
- Se SSH falha ou timeout, KV fica com dados antigos/vazios
- Não há mecanismo de "health check" do cache

**Impacto**:
- Settings page mostra "0 servers" (dados vazios no KV)
- Auto-fill de prometheus_host falha (sem external_labels)
- Usuário precisa clicar em "Atualizar" manualmente

**Status**: ⚠️ PARCIALMENTE RESOLVIDO - Lê do KV primeiro, mas KV pode estar vazio

### Problema #4: Timeouts Agressivos no Frontend

**Descrição**: Frontend configurado com timeouts que não correspondem à realidade do backend

**Timeouts Configurados**:

| Componente | Timeout Original | Timeout Atual | Backend Real |
|-----------|------------------|---------------|--------------|
| api.ts (global) | 30000ms | 30000ms | N/A |
| getNodes() | 30000ms | 45000ms | 2-5s (primeira vez) |
| NodeSelector | 15000ms | 60000ms | 2-5s |
| useMetadataFields | 30000ms | 60000ms | 0.8s (KV) ou 20-30s (SSH) |

**Problema**: Timeouts foram sendo aumentados de 15s → 30s → 45s → 60s ao invés de resolver o problema de raiz

**Impacto**:
- ❌ Usuário espera até 60s para ver erro
- ❌ Não resolve o problema, apenas mascara
- ❌ Experiência terrível mesmo "funcionando"

**Status**: ⚠️ PROBLEMA NÃO RESOLVIDO - Aumentar timeout NÃO é solução

### Problema #5: Falta de Feedback Visual

**Descrição**: Usuário não sabe que sistema está processando

**Experiência Atual**:

```
Usuário clica em "Exporters"
         │
         ▼
Tela branca (0-30s)  ← SEM LOADING, SEM FEEDBACK!
         │
         ▼
Erro de timeout OU dados aparecem
```

**O que falta**:
- ✅ Loading skeleton durante carregamento
- ✅ Progresso de extração SSH ("Conectando em servidor 1/3...")
- ✅ Mensagem explicativa ("Primeira carga pode demorar 30s")
- ✅ Botão "Cancelar" se timeout
- ✅ Cache indicator ("Dados com 2min de idade, clique para atualizar")

**Status**: ❌ NÃO IMPLEMENTADO

---

## TENTATIVAS DE SOLUÇÃO

### Tentativa #1: Aumentar Timeouts (FALHOU)

**Data**: Durante sessão (múltiplas iterações)

**Mudanças**:
```typescript
// 1ª tentativa: 15s → 30s
timeout: 15000 → timeout: 30000

// 2ª tentativa: 30s → 45s
timeout: 30000 → timeout: 45000

// 3ª tentativa: 45s → 60s
timeout: 45000 → timeout: 60000
```

**Resultado**: ❌ FALHOU
- Problema persiste
- Apenas adia o erro
- Usuário espera mais para ver falha

**Lição**: Aumentar timeout NÃO resolve problema de performance

### Tentativa #2: Cache no Backend `/nodes` (PARCIAL)

**Data**: Durante sessão

**Implementação**:
```python
# backend/api/nodes.py

# Cache global de 30 segundos
_nodes_cache = None
_nodes_cache_time = 0
NODES_CACHE_TTL = 30

@router.get("/nodes")
async def get_nodes():
    current_time = time.time()

    # Retorna do cache se válido
    if _nodes_cache and (current_time - _nodes_cache_time) < 30:
        return _nodes_cache

    # Busca dados e atualiza cache
    ...
```

**Resultado**: ✅ PARCIAL SUCCESS
- **Primeira requisição**: 2.3s
- **Requisições seguintes (30s)**: <10ms
- **Mas**: Primeira requisição ainda lenta

**Arquivos Modificados**:
- `backend/api/nodes.py` (linhas 13-66)

### Tentativa #3: Leitura do KV Primeiro (PARCIAL)

**Data**: Durante sessão

**Implementação**:
```python
# backend/api/prometheus_config.py linha 244-265

@router.get("/fields")
async def get_available_fields(force_refresh: bool = False):
    # NOVO: Tentar ler do KV primeiro
    if not force_refresh:
        try:
            kv_data = await kv_manager.get_json('skills/cm/metadata/fields')
            if kv_data and kv_data.get('fields'):
                return FieldsResponse(
                    fields=kv_data['fields'],
                    from_cache=True
                )
        except:
            pass  # Cai no fluxo SSH

    # Fluxo SSH (lento)
    extraction_result = multi_config.extract_all_fields_with_status()
    ...
```

**Resultado**: ✅ FUNCIONA quando KV está populado
- **Com KV populado**: 0.8s
- **Com KV vazio**: 20-30s (SSH)
- **Problema**: KV nem sempre está populado

**Teste Realizado**:
```bash
$ curl -w "\nTempo: %{time_total}s\n" http://localhost:5000/api/v1/prometheus-config/fields -o nul
Tempo: 0.888996s  # ← RÁPIDO! (lendo do KV)
```

**Arquivos Modificados**:
- `backend/api/prometheus_config.py` (linhas 244-265)

### Tentativa #4: Context API para Requisições (IMPLEMENTADO MAS NÃO TESTADO)

**Data**: Final da sessão

**Problema Identificado**:
```typescript
// ANTES: 3 hooks faziam 3 requisições
const { tableFields } = useTableFields('exporters');   // Request 1
const { formFields } = useFormFields('exporters');     // Request 2
const { filterFields } = useFilterFields('exporters'); // Request 3
```

**Solução Implementada**:
```typescript
// MetadataFieldsContext.tsx (NOVO ARQUIVO)
export function MetadataFieldsProvider({ children }) {
  const [fields, setFields] = useState([]);

  useEffect(() => {
    // UMA ÚNICA requisição ao montar
    axios.get('/api/v1/prometheus-config/fields')
      .then(res => setFields(res.data.fields));
  }, []);

  return (
    <Context.Provider value={{ fields }}>
      {children}
    </Context.Provider>
  );
}

// useMetadataFields.ts (MODIFICADO)
export function useTableFields(context) {
  const { fields } = useMetadataFieldsContext(); // ← Lê do Context

  // Filtra localmente (sem requisição)
  return fields.filter(f => f.show_in_table);
}
```

**Resultado**: ✅ IMPLEMENTADO E CORRIGIDO
- Código compilou sem erros TypeScript
- Erro de `require is not defined` foi corrigido (usava CommonJS ao invés de ES modules)
- Aplicação reiniciada pelo usuário - Backend e frontend rodando
- **AGUARDANDO TESTE DE VALIDAÇÃO**: Confirmar que apenas 1 requisição é feita ao invés de 3

**Arquivos Criados/Modificados**:
- `frontend/src/contexts/MetadataFieldsContext.tsx` (NOVO - Context centralizado)
- `frontend/src/App.tsx` (linha 140 - adicionado MetadataFieldsProvider)
- `frontend/src/hooks/useMetadataFields.ts` (linhas 225, 251, 275 - modificados 3 hooks)

### Tentativa #5: Substituir `addonAfter` por `Space.Compact` (SUCESSO)

**Data**: Durante sessão

**Problema**: Warning do Ant Design
```
Warning: [antd: Input] `addonAfter` is deprecated.
Please use `Space.Compact` instead.
```

**Solução**:
```typescript
// ANTES
<Input
  addonAfter={
    <Upload>
      <Button>Upload</Button>
    </Upload>
  }
/>

// DEPOIS
<Space.Compact>
  <Input />
  <Upload>
    <Button>Upload</Button>
  </Upload>
</Space.Compact>
```

**Resultado**: ✅ SUCESSO - Warning removido

**Arquivos Modificados**:
- `frontend/src/pages/Installer.tsx` (linhas 2406-2433)

---

## ESTADO ATUAL

### O Que Funciona ✅

1. **Backend endpoints respondem**:
   - `/api/v1/nodes`: 2.3s (primeira vez), <10ms (cache)
   - `/api/v1/prometheus-config/fields`: 0.8s (do KV)

2. **Cache de 30s no `/nodes`**: Requisições subsequentes são instantâneas

3. **Leitura do KV no `/fields`**: Quando KV está populado, resposta é rápida

4. **External labels extraídos corretamente**:
   ```json
   {
     "172.16.1.26": {"site": "palmas", "cluster": "palmas-master", ...},
     "172.16.200.14": {"site": "rio", ...},
     "11.144.0.21": {"site": "dtc", ...}
   }
   ```

### O Que NÃO Funciona ❌ (REQUER VALIDAÇÃO)

1. **Cold start ainda lento**: Primeira carga após restart demora 20-30s+ (SE KV vazio)

2. **Context API implementado mas não testado**: ⚠️ CRÍTICO - Precisa verificar se apenas 1 requisição é feita
   - Implementado corretamente (MetadataFieldsProvider + hooks modificados)
   - Aplicação reiniciada e rodando
   - Necessário teste manual: Abrir DevTools → Network → Acessar /exporters → Contar requisições

3. **KV nem sempre populado**: Após restart, KV pode estar vazio/desatualizado

4. **Falta feedback visual**: Usuário não vê progresso durante carregamento inicial

### Arquivos Modificados na Sessão

**Backend**:
1. `backend/api/nodes.py` - Cache de 30s
2. `backend/api/prometheus_config.py` - Leitura do KV primeiro
3. `backend/core/multi_config_manager.py` - Extração de external_labels (JÁ EXISTIA)

**Frontend**:
1. `frontend/src/components/NodeSelector.tsx` - Timeout 15s → 60s
2. `frontend/src/services/api.ts` - Timeout getNodes 30s → 45s
3. `frontend/src/hooks/useMetadataFields.ts` - Context API
4. `frontend/src/contexts/MetadataFieldsContext.tsx` - NOVO ARQUIVO
5. `frontend/src/App.tsx` - Provider adicionado
6. `frontend/src/pages/Installer.tsx` - Space.Compact
7. `frontend/src/pages/Settings.tsx` - Colunas redimensionáveis (ResizableTitle)

### Hipóteses Não Testadas

1. **Context API resolve requisições duplicadas?** - NÃO TESTADO
   - Implementado mas pode ter bugs
   - Usuário reportou erro antes de validar

2. **KV precisa ser populado manualmente?** - POSSÍVEL
   - Backend só popula KV quando faz SSH
   - Se SSH falhar, KV fica vazio
   - Pode precisar de job inicialização

3. **ThreadPoolExecutor tem overhead?** - POSSÍVEL
   - 3 threads SSH em paralelo
   - GIL do Python pode causar contenção
   - Pode ser mais rápido async puro

4. **Paramiko é lento?** - POSSÍVEL
   - SSH via paramiko pode ter overhead
   - AsyncSSH pode ser mais rápido
   - Ou usar subprocess + ssh nativo

---

## ANÁLISE DE ROOT CAUSE

### Por Que o Sistema é Lento?

**Resposta Curta**: Porque faz operações I/O síncronas (SSH) durante requisições HTTP.

**Resposta Longa**:

```
CAUSA RAIZ #1: Arquitetura Síncrona
├─► Frontend faz requisição HTTP
├─► Backend ESPERA (bloqueia) SSH terminar
├─► SSH demora 20-30s (I/O de rede + leitura de arquivo)
└─► Apenas depois retorna resposta HTTP

SOLUÇÃO IDEAL: Arquitetura Assíncrona
├─► Background job extrai dados a cada X minutos
├─► Salva no KV (persistent storage)
├─► Frontend faz requisição HTTP
├─► Backend lê do KV (cache) instantaneamente
└─► Retorna resposta HTTP em <100ms
```

### Por Que Não Foi Implementado Corretamente?

**Análise das Decisões de Design**:

1. **Decisão**: Extrair campos em tempo real via SSH
   - **Prós**: Dados sempre atualizados
   - **Contras**: Lento, não escala, timeout
   - **Alternativa**: Background job + cache

2. **Decisão**: Cache em memória (`_fields_cache`)
   - **Prós**: Rápido após primeira requisição
   - **Contras**: Perdido ao reiniciar, não compartilhado entre instâncias
   - **Alternativa**: Cache persistente (Redis, KV)

3. **Decisão**: Múltiplos hooks fazem requisições independentes
   - **Prós**: Desacoplamento, cada hook autônomo
   - **Contras**: Requisições duplicadas, overhead
   - **Alternativa**: Context API (implementado mas não testado)

4. **Decisão**: Timeouts altos (60s)
   - **Prós**: Evita erro timeout
   - **Contras**: Usuário espera 60s, não resolve problema raiz
   - **Alternativa**: Operações assíncronas + feedback visual

### Comparação: O Que Deveria Ser vs O Que É

| Aspecto | Estado Atual | Estado Ideal |
|---------|-------------|--------------|
| **Extração de Campos** | Durante requisição HTTP (20-30s) | Background job (invisível para usuário) |
| **Cache** | Memória + KV inconsistente | KV sempre populado + TTL configurável |
| **Requisições Frontend** | 3x o mesmo endpoint | 1x via Context API |
| **Feedback Visual** | Tela branca por 30s | Loading skeleton + progresso |
| **Timeout** | 60s (mascarar problema) | 5s (porque backend é rápido) |
| **Tempo de Carga** | 20-60s | <2s |

---

## PRÓXIMOS PASSOS RECOMENDADOS

### Prioridade CRÍTICA (P0) - Fazer Sistema Funcionar

#### Passo 1: Validar Context API

**Objetivo**: Confirmar que requisições duplicadas foram eliminadas

**Como Testar**:
```bash
# 1. Limpar cache do navegador
# 2. Abrir DevTools → Network tab
# 3. Acessar http://localhost:8081/exporters
# 4. Contar quantas vezes /prometheus-config/fields é chamado

# ESPERADO: 1 chamada
# SE AINDA 3 CHAMADAS: Context API não funcionou
```

**Se Context API não funciona**:
```typescript
// OPÇÃO 1: Garantir que Provider está no lugar certo
// App.tsx deve ter:
<MetadataFieldsProvider>
  <Routes>
    <Route path="/exporters" element={<Exporters />} />
  </Routes>
</MetadataFieldsProvider>

// OPÇÃO 2: Verificar se hooks estão importando o Context
// useMetadataFields.ts deve ter:
import { useMetadataFieldsContext } from '../contexts/MetadataFieldsContext';

// NÃO DEVE ter:
const response = await axios.get(...); // ← REMOVE ISSO
```

#### Passo 2: Garantir KV Sempre Populado

**Objetivo**: KV nunca deve estar vazio

**Implementação**:

```python
# backend/app.py - Adicionar startup event

@app.on_event("startup")
async def startup_event():
    """
    Pré-popular KV ao iniciar servidor
    Roda em background para não atrasar startup
    """
    import asyncio
    from api.prometheus_config import pre_warm_cache

    # Roda em background (não bloqueia startup)
    asyncio.create_task(pre_warm_cache())

    logger.info("[STARTUP] Background job de cache iniciado")

# backend/api/prometheus_config.py - Adicionar função

async def pre_warm_cache():
    """
    Popula KV em background ao iniciar servidor
    """
    import time

    # Espera 5s para servidor terminar startup
    await asyncio.sleep(5)

    logger.info("[PRE-WARM] Iniciando extração de campos em background...")

    try:
        # Força extração via SSH
        result = multi_config.extract_all_fields_with_status()

        # Salva no KV
        kv_manager = KVManager()
        await kv_manager.put_json(
            key='skills/cm/metadata/fields',
            value={
                'fields': [f.to_dict() for f in result['fields']],
                'extraction_status': result,
                'last_updated': datetime.now().isoformat()
            }
        )

        logger.info(f"[PRE-WARM] ✓ Cache populado com {len(result['fields'])} campos")
    except Exception as e:
        logger.error(f"[PRE-WARM] ✗ Erro ao popular cache: {e}")
```

**Benefício**:
- KV sempre populado após restart
- Primeira requisição HTTP é rápida (<1s)
- Extração SSH acontece em background (invisível)

#### Passo 3: Adicionar Feedback Visual

**Objetivo**: Usuário sabe que sistema está carregando

**Implementação**:

```typescript
// frontend/src/contexts/MetadataFieldsContext.tsx

export function MetadataFieldsProvider({ children }) {
  const [fields, setFields] = useState([]);
  const [loading, setLoading] = useState(true);
  const [progress, setProgress] = useState(0); // NOVO
  const [message, setMessage] = useState('');   // NOVO

  useEffect(() => {
    loadFields();
  }, []);

  const loadFields = async () => {
    setLoading(true);
    setMessage('Conectando ao servidor...');
    setProgress(10);

    try {
      const response = await axios.get('/api/v1/prometheus-config/fields', {
        timeout: 60000,
        onDownloadProgress: (progressEvent) => {
          // Atualiza progresso
          const percentCompleted = Math.round(
            (progressEvent.loaded * 100) / progressEvent.total
          );
          setProgress(10 + percentCompleted * 0.9);
        }
      });

      setMessage('Processando campos...');
      setProgress(95);

      if (response.data.from_cache) {
        setMessage('Carregado do cache');
      } else {
        setMessage('Campos extraídos via SSH');
      }

      setFields(response.data.fields);
      setProgress(100);
    } catch (err) {
      setMessage(`Erro: ${err.message}`);
    } finally {
      setLoading(false);
    }
  };

  return (
    <Context.Provider value={{ fields, loading, progress, message }}>
      {loading && (
        <Alert
          type="info"
          message={message}
          description={`${progress}% concluído`}
          showIcon
        />
      )}
      {children}
    </Context.Provider>
  );
}
```

### Prioridade ALTA (P1) - Melhorar Performance

#### Passo 4: Background Job para Extração

**Objetivo**: SSH nunca acontece durante requisição HTTP

**Opção A: APScheduler (Python)**

```python
# backend/app.py

from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('interval', minutes=5)
async def update_fields_cache():
    """
    Atualiza cache de campos a cada 5 minutos
    """
    logger.info("[SCHEDULER] Atualizando cache de campos...")

    try:
        result = multi_config.extract_all_fields_with_status()

        kv_manager = KVManager()
        await kv_manager.put_json(
            key='skills/cm/metadata/fields',
            value={
                'fields': [f.to_dict() for f in result['fields']],
                'last_updated': datetime.now().isoformat()
            }
        )

        logger.info("[SCHEDULER] ✓ Cache atualizado")
    except Exception as e:
        logger.error(f"[SCHEDULER] ✗ Erro: {e}")

@app.on_event("startup")
def start_scheduler():
    scheduler.start()
    logger.info("[SCHEDULER] Iniciado - atualização a cada 5min")

@app.on_event("shutdown")
def stop_scheduler():
    scheduler.shutdown()
```

**Opção B: Celery (mais robusto)**

```python
# backend/celery_app.py

from celery import Celery
from celery.schedules import crontab

celery = Celery('consul_manager', broker='redis://localhost:6379/0')

celery.conf.beat_schedule = {
    'update-fields-cache': {
        'task': 'tasks.update_fields_cache',
        'schedule': crontab(minute='*/5'),  # A cada 5 minutos
    },
}

# backend/tasks.py

@celery.task
def update_fields_cache():
    """
    Task assíncrona para atualizar cache
    """
    # Mesmo código do APScheduler
    ...
```

**Benefício**:
- SSH acontece em background a cada 5min
- Requisições HTTP sempre leem do cache (<1s)
- Sistema escala melhor

#### Passo 5: Remover Timeouts Altos

**Objetivo**: Voltar timeouts para valores normais (5-10s)

**Implementação**:

```typescript
// frontend/src/services/api.ts

const api = axios.create({
  baseURL: API_URL,
  timeout: 10000,  // 10s (suficiente se backend lê do cache)
});

// frontend/src/hooks/useMetadataFields.ts

const response = await axios.get('/api/v1/prometheus-config/fields', {
  timeout: 10000,  // 10s (não 60s!)
});
```

**Justificativa**:
- Se backend lê do KV, responde em <1s
- Timeout de 10s é generoso
- Se ultrapassar 10s, problema é no backend (não no timeout)

### Prioridade MÉDIA (P2) - Otimizações Adicionais

#### Passo 6: AsyncSSH ao invés de Paramiko

**Objetivo**: SSH mais rápido

```python
# backend/core/multi_config_manager.py

# SUBSTITUIR paramiko por asyncssh

import asyncssh

async def _process_single_server_async(self, host):
    """
    Versão async usando asyncssh
    """
    async with asyncssh.connect(
        host.hostname,
        username=host.username,
        password=host.password,
        port=host.port
    ) as conn:
        # Lê arquivo remoto
        async with conn.start_sftp_client() as sftp:
            async with sftp.open('/etc/prometheus/prometheus.yml') as f:
                content = await f.read()

        # Parse YAML
        config = yaml.safe_load(content)

        return config

# Processar todos os servidores em paralelo (async puro)
tasks = [
    self._process_single_server_async(host)
    for host in self.hosts
]

results = await asyncio.gather(*tasks)
```

**Benefício**:
- AsyncSSH é nativo async (não usa threads)
- Potencialmente mais rápido que paramiko
- Melhor integração com FastAPI

#### Passo 7: Reduzir Dados Transferidos

**Objetivo**: Ler apenas o necessário dos arquivos YAML

```python
# Ao invés de ler TODO o prometheus.yml (pode ter 10000+ linhas)
# Ler apenas a seção relevante

async def extract_fields_optimized(ssh_client):
    """
    Extrai apenas relabel_configs via grep remoto
    """
    # Comando remoto para extrair apenas relabel_configs
    result = await ssh_client.run(
        "grep -A 10 'relabel_configs:' /etc/prometheus/prometheus.yml"
    )

    # Parse apenas essa seção
    ...
```

**Benefício**:
- Menos dados transferidos via SSH
- Parse YAML mais rápido
- Pode reduzir tempo de 20s para 5-10s

### Prioridade BAIXA (P3) - Nice to Have

#### Passo 8: Server-Sent Events para Progresso em Tempo Real

```python
# backend/api/prometheus_config.py

@router.get("/fields/stream")
async def stream_fields_extraction(request: Request):
    """
    Stream de progresso da extração
    """
    async def event_generator():
        yield f"data: {json.dumps({'progress': 0, 'message': 'Iniciando...'})}\n\n"

        # ... extração SSH com yields de progresso ...

        yield f"data: {json.dumps({'progress': 100, 'done': True})}\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream"
    )
```

```typescript
// frontend/src/contexts/MetadataFieldsContext.tsx

const eventSource = new EventSource('/api/v1/fields/stream');

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  setProgress(data.progress);
  setMessage(data.message);
};
```

#### Passo 9: Métricas e Observabilidade

```python
# Adicionar logging estruturado

import structlog

logger = structlog.get_logger()

@router.get("/fields")
async def get_available_fields():
    with logger.contextualize(endpoint="get_fields"):
        start = time.time()

        logger.info("fields_request_start")

        try:
            result = await load_fields()

            duration = time.time() - start
            logger.info(
                "fields_request_success",
                duration_ms=duration * 1000,
                fields_count=len(result),
                from_cache=result.get('from_cache')
            )

            return result
        except Exception as e:
            logger.error("fields_request_error", error=str(e))
            raise
```

---

## RESUMO PARA PRÓXIMA IA

### Você Precisa Saber

1. **Problema Principal**: Sistema demora 20-60s para carregar páginas após restart

2. **Causa Raiz**: Backend faz SSH síncrono durante requisições HTTP

3. **O Que Foi Tentado**:
   - ✅ Cache de 30s no `/nodes`
   - ✅ Leitura do KV no `/fields`
   - ✅ Context API para evitar requisições duplicadas
   - ❌ Aumentar timeouts (não resolve)

4. **O Que Funciona**:
   - Backend responde rápido quando KV está populado (0.8s)
   - Cache funciona corretamente

5. **O Que NÃO Funciona**:
   - Cold start ainda lento (KV pode estar vazio)
   - Context API implementado mas não testado
   - Usuário reporta "página não carrega"

### Próximos Passos Prioritários

1. **TESTAR Context API** - Verificar se requisições duplicadas foram eliminadas
2. **PRÉ-POPULAR KV** - Startup event para garantir KV nunca vazio
3. **FEEDBACK VISUAL** - Loading states e progresso
4. **BACKGROUND JOB** - APScheduler para extrair campos a cada 5min

### Arquivos Críticos

**Backend**:
- `backend/api/prometheus_config.py` - Endpoint `/fields` (linha 219-300)
- `backend/core/multi_config_manager.py` - Extração SSH (linha 506-610)
- `backend/api/nodes.py` - Endpoint `/nodes` com cache

**Frontend**:
- `frontend/src/contexts/MetadataFieldsContext.tsx` - Context API (NOVO)
- `frontend/src/hooks/useMetadataFields.ts` - Hooks que consomem Context
- `frontend/src/App.tsx` - Provider configurado
- `frontend/src/pages/Exporters.tsx` - Página problemática

### Comandos Úteis para Debugging

```bash
# Testar tempo de resposta do backend
curl -w "\nTempo: %{time_total}s\n" http://localhost:5000/api/v1/prometheus-config/fields -o nul

# Ver dados do KV
curl http://localhost:5000/api/v1/kv/value?key=skills/cm/metadata/fields | python -m json.tool

# Reiniciar aplicação
cd c:\consul-manager-web && restart-app.bat

# Limpar cache do Consul KV (forçar re-extração)
curl -X DELETE http://172.16.1.26:8500/v1/kv/skills/cm/metadata/fields?token=8382a112-81e0-cd6d-2b92-8565925a0675
```

---

## CONCLUSÃO

O sistema tem uma **arquitetura fundamentalmente problemática** onde operações I/O lentas (SSH) estão no caminho crítico de requisições HTTP.

**A solução NÃO é**:
- ❌ Aumentar timeouts
- ❌ Adicionar mais cache em memória
- ❌ Otimizar código Python

**A solução É**:
- ✅ Background job para extração assíncrona
- ✅ KV sempre populado e atualizado
- ✅ Requisições HTTP apenas leem cache
- ✅ Feedback visual durante carregamento

**Tempo estimado para implementação correta**: 4-8 horas de trabalho focado

**Impacto esperado**: Tempo de carga de 20-60s → <2s

---

**FIM DA DOCUMENTAÇÃO**
